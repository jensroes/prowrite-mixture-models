# Statistical models

We implemented four statistical models using the Bayesian framework [e.g. @farrell2018computational; @gelman2014; @lee2014bayesian] to evaluate the serial or the parallel view. In other words, we used statistical models to map between keystroke data and the theoretically assumed cognitive process that underlies the generation of theses data. These models are presented in more detail in this section.

## Single-distribution Gaussian model

Under the serial view, all planning relevant for the to-be-produced utterance must be completed prior to typing onset. The duration of the resulting interkey interval depends on, among others, psycholinguistic factors; i.e. interkey intervals that are located before easily retrievable high-frequency words tend to be short; similar for words with fewer graphemes, syllables, and morphemes [@torrance2018timed; @roeser2018advance; @nottbusch2005syllabic]. We can capture the variability associated with word-features by assuming that before-word interkey intervals can be described as coming from a normal (Gaussian) distribution that can be fully characterised by an unknown central tendency $\mu$ of interkey intervals associated with word-level planning and a dispersion $\sigma_\text{e}^2$, that captures the residual variance in the data that is not captured by the model. This can be expressed as $\text{iki}_\text{before word} \sim \mathcal{N}(\mu, \sigma_\text{e}^2)$ where $\text{iki}_\text{before word}$ are all interkey intervals immediately proceeding a word. Of importance is the estimated value of the central tendency parameter $\mu$ representing in this case the average time needed to mentally prepare a word.

We can extend this simple model of word planning to other linguistic locations. Edges of larger linguistic units are typically understood as being associated with planning on higher levels. For example, at sentence boundaries, planning needs to happen for word-level properties -- which we captured before with the parameter $\mu$ -- but also for higher level information such as what meaning it is that should be conveyed, which word to plan and output first, and potentially even dependencies of the sentence-initial noun [@roeser2018advance; @not07]. We can capture factors that we assume to impact interkey intervals by decomposing $\mu$ into the general form $\mu = \alpha + \beta \times \text{x}$. For example, to capture the additional planning needed at sentence boundaries we can add the predictor $\text{x}_\text{sentence[0,1]}$ so that $\mu = \alpha + \beta \times \text{x}_\text{sentence[0,1]}$. This states that when the value of $\text{x}_\text{sentence}$ takes on 0, the equation reduces to $\mu = \alpha$ which is then the average interkey interval for word boundaries but, when $\text{x}_\text{sentence}$ takes on the value 1, the average interkey interval for word boundaries $\alpha$ is incremented by a changed in the outcome variable of $\beta$ msecs. The value of the $\beta$ parameter represents, therefore, the additional planning necessary for sentences. The application of such a statistical model to the data therefore provides us with an estimate of the parameter value that can be used for statistical inference (e.g. to determine whether there is evidence for a statistically meaningful difference for interkey intervals immediately proceeding words vs sentences).

We implemented such a model -- a standard Gaussian mixed-effects model -- as described in equation \ref{eq:unimodgaus}. This model assumes that interkey intervals $\text{iki}_i$ with $i \in 1 \ldots N$ where $N$ is the total number of interkey intervals come from a Gaussian distribution with a mean $\mu$,

\begin{equation}
\begin{aligned}
(\#eq:unimodgaus)
\text{iki}_i \sim\text{ } & \mathcal{N}(\mu_i, \sigma_\text{e}^2)\\
\text{where: } & \mu_i = \beta_\text{location[i]} + u_\text{participant[i]}\\
& u_\text{participant[i]} \sim \mathcal{N}(0, \sigma_\text{p}^2)\\
\text{constraint: } & \sigma_\text{e}^2, \sigma_\text{p}^2>0
\end{aligned}
\end{equation}

which is a linear function of the $i^\text{th}$ transition location (we used there levels: before sentence, before word, within word) captured by $\beta_\text{location}$, and the random-intercept term $u_\text{participant}$ which is constrained to come from a normal distribution with a mean of 0 and the standard deviation $\sigma_\text{p}^2$. For the random-intercept term, $\text{participant[i]}$ is the participant associated with the $i^\text{th}$ interkey interval. The posterior of $u_\text{participant}$ is therefore the difference between the posterior interkey-interval estimate of each participant (i.e. a positive value indicates that a participant is slower than average; a negative value indicates that a participant is faster than average) and allows to capture the fact that some writers are faster and other writers are slower. Importantly this model returns posterior probability distributions with interkey-interval estimates for each $\beta$, one for each transition location. 

Standard-deviation parameters were constrained to be positive because standard deviations can, by definition, never be negative. 

## Single-distribution log-Gaussian model

The previous model assumes a Gaussian probability function as the underlying data-generating process. The model presented in this section is identical to the previous model but instead of assuming a Gaussian probability function, we assume that the process that generates the follows a log-normal (log-Gaussian) distribution. 

There are, at least, two reason for why a log-Gaussian distribution is more appropriate than a standard Gaussian: (1) the log-Gaussian have a natural lower bound. This is a desirable property because the distance between two subsequent keystroke events is by definition positive. The lower bound of the distribution of interkey intervals is delimited by a writer's ability to move their fingers and keyboard polling. (2) the log-scale is known to be a better match for data from human motor behaviour and response time data than the normal distribution [@wagenmakers2007linear; @baayen2008analyzing]. This is because in a Gaussian distribution the distance between adjacent units is linear. In other words a difference of 25 msecs is the same between 100 and 125 msecs as between 5 secs and 5,025 msecs. This does not map onto the psychological interpretation for short and long interkey intervals. For example effects that result from difficulty on the motor level (e.g. executing familiar key combinations such as *ng* compared to *gn*) are typically smaller than differences that are due to higher levels of processing (e.g. struggling to retrieve a word in an L1 or L2). In other words, an effect of 25 msecs is relatively large in the context of lower-level motor events but small in the context of higher-level cognitive activity such as planning what to say next. Log-Gaussian distributions are a natural way of translating a linear scale to an exponential scale so that a 25 msecs difference on the lower end (motor activity) is more psychologically meaningful than a 25 msecs difference on the upper end of the distribution interkey intervals (retrieving words, planning contents).

This model can be described as in equation \ref{eq:unimodloggaus} in which the distribution $\mathcal{N}()$ was replaced by $\log\mathcal{N}()$ to represent a log-normal distribution.

\begin{equation}
\begin{aligned}
(\#eq:unimodloggaus)
\text{iki}_i \sim\text{ } & \log\mathcal{N}(\mu_i, \sigma_\text{e}^2) \\
\text{where: } &
\mu_i = \beta_\text{location[i]} + u_\text{participant[i]}\\
& u_\text{participant[i]} \sim \mathcal{N}(0, \sigma_\text{p}^2) \\
\text{constraint: } & \sigma_\text{e}^2, \sigma_\text{p}^2>0
\end{aligned}
\end{equation}

## Single-distribution unequal-variance log-Gaussian model

The third model is identical to the model presented in the previous section but relaxed the equal-variance assumption associated with transition location. In particular the previous models assumed that the variances associated with each transition location were identical. This assumption does however not fit with what we know about data from human motor behaviour. Longer latencies are known to be associated with a larger variance for human motor behaviour [@wagenmakers2007linear; @wing1973response; @schoner2002timing]. For interkey intervals pauses at edges of larger linguistic units can therefore be assumed to be associated with a larger variance. In equation \ref{eq:unimoduv}, we introduced this assumption by allowing the standard deviations $\sigma_{e_\text{location}}^2)$ to vary by transition location. 

\begin{equation}
\begin{aligned}
(\#eq:unimoduv)
\text{iki}_i \sim\text{ } & \log\mathcal{N}(\mu_i, \sigma_{e_\text{location[i]}}^2) \\
\text{where: } & \mu_i = \beta_\text{location[i]} + u_\text{participant[i]}\\
 & u_\text{participant[i]} \sim \mathcal{N}(0, \sigma_\text{p}^2) \\
 \text{constraint: } & \sigma_\text{e}^2, \sigma_\text{p}^2>0
\end{aligned}
\end{equation}


## Two-distribution log-Gaussian mixture model 

The following model is an extension of the previous single-distribution model. In contrast to the models introduced for the serial view of writing, the parallel view assumes that planning occurs while previously planned language units are being executed in writing. For the model presented in this section we removed the constraint that all planning must be completed before writing onset. In other words, instead of assuming that different linguistic edges shift the distribution over average interkey intervals towards larger values -- as in the previous models -- the parallel view assumes the frequency of observing a hesitant intekey interval and the size of this hesitation depends on text location of the key transition. This was achieved by introducing the assumption that interkey intervals come from a weighted combination (i.e. mixture) of two distributions associated with two different states: 

1. Activation flows into keystrokes without interruption. These fluent interkey intervals are merely constrained by a writer's ability to move their fingers and were captured by $\beta$ in equation \ref{eq:bimodcon}. In other words, $\beta$ represents the average typing speed for fluent transitions between keys. Note that the $\beta$ parameter is represented in both log-Gaussian distributions in equation \ref{eq:bimodcon}. 

2. Interruptions in the activation flow from higher to lower levels result in longer keystroke intervals when information was not available in time, for example when competition occurs during lexical retrieval or when its orthographic representation was not easily available. The slowdown for these hesitant transitions is captured by $\delta$ in the first line of equation \ref{eq:bimodcon}. This $\delta$ parameter was constrained to be positive and added to the distribution of fluent key transitions $\beta$. It therefore represents the magnitude of the slowdown associated with hesitant transitions. The slowdown $\delta$ was allowed to vary by transition locations because hesitations at larger linguistic units are more likely to be associated with higher level planning which may delay output. 

The first line of equation \ref{eq:bimodcon} represents the distribution of hesitant interkey intervals; the second line represents fluent interkey intervals. 

\begin{equation}
\begin{aligned}
(\#eq:bimodcon)
\text{iki}_{i} \sim\text{ } & \theta_\text{location[i], participant[i]} \times \log\mathcal{N}(\beta + \delta_\text{location[i]} + u_\text{participant[i]}, \sigma_{e'_\text{location[i]}}^2) + \\
  & (1 - \theta_\text{location[i], participant[i]}) \times \log\mathcal{N}(\beta + u_\text{participant[i]}, \sigma_{e_\text{location[i]}}^2)\\
\text{where: } & u_\text{participant[i]} \sim \mathcal{N}(0, \sigma_\text{p}^2) \\
\text{constraint: } & \delta, \sigma_{e}^2, \sigma_\text{e'}^2, \sigma_\text{p}^2>0\\
		& \sigma_{e'}^2 > \sigma_{e}^2\\
		& 0 < \theta < 1
\end{aligned}
\end{equation}


These two distributions are associated with the mixing weight $\theta$ which must be larger than 0 and smaller than 1. $\theta$ is parameterised to represent the weighting of the distribution in the first line, hence representing the *hesitation probability*. This probability is inversely related to the mixing weight of the distribution of short interkey intervals by $1-\theta$ as the weights of both distributions must sum to 1. In line with the literature discussed in the introduction, we assume that the hesitation probability is likely to vary across linguistic locations. As hesitation frequency is subject to individual differences and writing style (and skills), we also assumed that some participants are more and others are less likely to hesitate at certain transition locations [@waes2019]. 

Lastly, we carried over the unequal variance assumption and let the standard deviations $\sigma_{e'}^2$ and $\sigma_{e}^2$ vary by transition location. We constrained the standard deviations so that $\sigma_{e'}$ which is associated with the distribution of hesitant interkey intervals is larger than the standard deviation associated with fluent transitions $\sigma_e$ for reasons discussed above.



<!-- ### Two-distributions log-Gaussian mixture model (unconstrained) -->

<!-- The size of a fluent key-transition does not necessarily vary by transition location. In other words, the parameter $\beta$ is the same for before-sentence, before-word, and within-word transitions. This is what we called a constrained model. However, letter bigrams and trigrams may be systematically executed faster than transitions between between space and a letter or complex keystrokes that comprise space and shift-letter combinations for upper case characters before sentences (we will address the latter possibility in the results section). This is because bigrams / trigrams might be stored, retrieved and executed as motor codes but not transitions to a space following a word or between a space or shift key press preceding a letter. Also, because of the necessarily larger number of within-word transitions, as opposed to before-word and sentence transitions, the posterior of the constrained model is dominated by within-word transition data. We therefore also implemented an unconstrained model that assumes that the size of fluent transitions varies across transition locations. -->

<!-- In this model we assume that $\beta$ varies by transition-location as illustrated in equation \ref{eq:bimoduncon}. -->

<!-- \begin{equation} -->
<!-- \begin{aligned} -->
<!-- (\#eq:bimoduncon) -->
<!-- \text{iki}_{i} \sim\text{ } & \theta_\text{location[i], participant[i]} \cdot \text{log}\mathcal{N}(\beta_\text{location[i]} + \delta_\text{location[i]} + u_\text{participant[i]}, \sigma_{e'_\text{location[i]}}^2) + \\ -->
<!--   & (1 - \theta_\text{location[i], participant[i]}) \cdot \text{log}\mathcal{N}(\beta_\text{location[i]} + u_\text{participant[i]}, \sigma_{e_\text{location[i]}}^2)\\ -->
<!-- 	\text{where: }  & u_\text{participant[i]} \sim \mathcal{N}(0, \sigma_\text{p}^2) \\ -->
<!-- \text{constraint: } & \delta, \sigma_{e}^2, \sigma_\text{e'}^2, \sigma_\text{p}^2>0\\ -->
<!-- 		& \sigma_{e'}^2 > \sigma_{e}^2\\ -->
<!-- 		& 0 < \theta < 1 -->
<!-- \end{aligned} -->
<!-- \end{equation} -->


