# Statistical models

We are using the Bayesian framework [e.g. @farrell2018computational; @gelman2014; @lee2014bayesian] to implement 5 statistical models of writing and to evaluate which -- the serial or the cascading view -- captures more successfully the data that arise during keyboard typing. In other words, we use statistical models to map between the data and the theoretically assumed process that generates the data to then compare the predictive power of those models. The models presented in this section build on one another so that later model include assumptions of earlier models.


## Serial model of writing

### Single distribution Gaussian

Under the serial view, all planning must be completed priors to the production onset of the corresponding planning unit. The resulting IKI is sometimes faster or slower depending on, among others, psycholinguistic factors. For example, the interval before a word is shorter for easily retrievable high-frequency words, or longer for low frequency words, shorter for words with fewer graphemes, syllables, and morphemes. There are word-specific factors that influence the IKI that precedes a word but these are beyond the scope of our analysis. We will capture the variability associated with word-features by assuming that before-word IKIs can be described as coming from a distribution that is normal (Gaussian) with two parameters, an unknown mean $\mu$, that describes the average IKI associated with word-level planning, and a standard deviation $\sigma_\text{e}^2$, that captures the variability associated with factors that we did not further specify in the model. This can be expressed as $\text{iki}_\text{before word} \sim \text{log}\mathcal{N}(\mu, \sigma_\text{e}^2)$. Of importance is the estimated posterior value of $\mu$ as this value captures that time it takes to mentally plan a word.

We can extend this simple model of word-planning to other linguistic location. We introduce earlier that larger linguistic edges are associated with planning on higher levels. For example, at sentence boundaries, planning needs to happen for word-level properties -- which was captured above as average IKI $\mu$ -- but also higher linguistic planning such as clause-level meaning, and dependencies of the sentence-initial noun [@roeser2018advance; @not07]. Regression formulas can, and commonly are, used to decompose $\mu$ and capture that there is a change in the outcome variable associated with another factors. We can decompose $\mu$ as $\mu = \alpha + \beta \cdot \text{x}_\text{sentence[0,1]}$ so that when $\text{x}_\text{sentence}$ takes on the value 0, the equation reduces to $\mu = \alpha$ which is the average IKI for word boundaries. However when $\text{x}_\text{sentence}$ takes on the value 1, the average IKI for word boundaries $\alpha$ is incremented by a sentence-related slowdown of $\beta$ msecs. Therefore the value of the $\beta$ parameter represents the additional cognitive demand associated with sentence-initial planning. The application of such a statistical model to the data will then provide us with an estimate of the parameter value that can be used for statistical inference (e.g. whether there is a statistically meaningful difference between IKI associated with words and sentences).

We implemented the average keytransition associated with a given text locations as $\beta_\text{location}$ in equation \ref{eq:unimodgaus} where $\text{location}$ is taking on an index for each transition location. Therefore, the model will return one $\beta$ per transition location that capture the posterior distribution of average IKIs. Also the decomposition of $\mu$ allows us to address the fact that some writers are faster than other writers by introducing a parameter for what is typically called random intercepts $u_\text{participant}$. The random intercepts term $u_\text{participant}$ is constrained so that the value it takes on comes from a normal distribution with a mean of 0 and a standard deviation of $\sigma_\text{p}^2$. This value is therefore the difference between the overall posterior estimate and estimate average IKI of a particular participant (i.e. a positive value indicates that a participant is slower than average, a negative value indicates that a participant is faster than average).

The final model is shown in equation \ref{eq:unimodgaus} and represents a Gaussian mixed effects model  


\begin{equation}
\begin{aligned}
(\#eq:unimodgaus)
\text{iki}_i \sim\text{ } & \text{log}\mathcal{N}(\mu_i, \sigma_\text{e}^2)\\
\text{where: } & \mu_i = \beta_\text{location[i]} + u_\text{participant[i]}\\
& u_\text{participant[i]} \sim \text{N}(0, \sigma_\text{p}^2)\\
\text{constraint: } & \sigma_\text{e}^2, \sigma_\text{p}^2>0
\end{aligned}
\end{equation}

where $i$ iterates over every key-transition $i \in 1 \dots N$ with $N$ being the total number of keystroke intervals, and thus $\text{location[i]}$ is the transition location associated with the $i$^\text{th} keystroke and $\text{participant[i]}$ is the participant associated with the $i$^\text{th} keystroke.

Standard-deviation parameters were constrained to be positive because standard deviations can never be negative. 


### Single distribution log-Gaussian

The previous model assumes that the data-generating process is a Gaussian distribution. The next model is largely identical to the previous model but instead of assuming a Gaussian, we assume that the data come from a log-normal (log-Gaussian) distribution. There are, at least, two arguments for using a log-Gaussian distribution: (1) log-Gaussians are zero-bound; in contrast to Gaussians, a log-Gaussian does not allow negative values. IKIs, as the distance between two subsequent key-down events, must be positive. The lower bound is delimited by a person's ability to move their fingers and keyboard polling. (2) the log-scale is known to be a better match for data from human behaviour and motor responses. In particular, a Gaussian distribution assumes that units are scaled linearly. For example, a difference of 25 msecs is the same between 100 and 125 msecs as between 5 secs and 5,025 msecs. This does not necessarily map onto the psychological interpretation for short and long keyintervals. For example effects that result on the motor level within words (e.g. typing a high vs a low frequency bigram) are smaller than differences that are due to high levels of processing (retrieving a word in an L1 or L2). In other words, although an effect of 25 msecs is large in the context overall fast keyintervals, it is small in the context of overall slow intervals. Log-Gaussian distributions are a natural way of translating a linear scale to an exponential scale so that a 25 msecs difference on the lower end of the IKI scale (motor activity) is more meaningful than a 25 msecs difference on the upper end of the IKI scale (retrieving words, planning sentences).

The model can be described as in equation \ref{eq:unimodloggaus} in which the distribution $\text{log}\mathcal{N}()$ was replaced by $\text{logN}()$.

\begin{equation}
\begin{aligned}
(\#eq:unimodloggaus)
\text{iki}_i \sim\text{ } & \text{log}\mathcal{N}(\mu_i, \sigma_\text{e}^2) \\
\text{where: } &
\mu_i = \beta_\text{location[i]} + u_\text{participant[i]}\\
& u_\text{participant[i]} \sim \mathcal{N}(0, \sigma_\text{p}^2) \\
\text{constraint: } & \sigma_\text{e}^2, \sigma_\text{p}^2>0
\end{aligned}
\end{equation}

### Single distribution unequal-variance log-Gaussian

The third model representing the serial view of writing is a single distribution unequal-variance model that, except for the unequal-variance assumption is identical to the model presented in the previous section. The previous models modelled IKIs as a function of transition location so that the estimated average IKI depends on the position of an IKI in the text. The variance associated with the estimated IKIs for each transition location was assumed to be identical (equal variance). This assumption is however not in line with what we know about data from human behaviour. Longer latencies are known to be associated with a larger variances for both response-time data in particular [@wagenmakers2007linear] and human motor behaviour in general [@wing1973response;@schoner2002timing]. For IKIs pauses at larger linguistic edges are plausibly associated with a larger variance because of the larger number of associated processes. Therefore, in equation \ref{eq:unimoduv}, we introduce the assumption that standard deviation $\sigma_{e_\text{location}}^2)$ varies by transition location. 

\begin{equation}
\begin{aligned}
(\#eq:unimoduv)
\text{iki}_i \sim\text{ } & \text{log}\mathcal{N}(\mu_i, \sigma_{e_\text{location[i]}}^2) \\
\text{where: } & \mu_i = \beta_\text{location[i]} + u_\text{participant[i]}\\
 & u_\text{participant[i]} \sim \mathcal{N}(0, \sigma_\text{p}^2) \\
 \text{constraint: } & \sigma_\text{e}^2, \sigma_\text{p}^2>0
\end{aligned}
\end{equation}


## Parallel cascading model of writing

The following two models are are extensions of the models introduced for the serial view. Crucially, the cascading view allows planning to happen in parallel to production. Therefore, we will reduce the constrain of the serial models that requires all planning to be completed before writing onset. This is done by assuming that IKIs come from a weighted combination of two distributions.


### Two-distributions log-Gaussian mixture model (constrained)

This model extends the assumption of the previous model that processing that involves higher levels of activation lead to longer pauses. Instead of assuming that there is one process that is shifted for IKIs of larger linguistic edges, we introduce the assumption that pauses at larger linguistic edges are more likely but not obligatory. This is achieved by modelling IKIs as coming from a weighted mixture of two distributions associated with two different states: 

1. Activation can flow into keystrokes without interruption. These fluent keystroke transitions are merely constrained by a person's ability to move their finger and will be captured by the $\beta$ parameter in equation \ref{eq:bimodcon}. Note that $\beta$ is represented in both log-Gaussian distributions in equation \ref{eq:bimodcon} referring to the same unknown parameter. 

2. Interruptions in the activation flow from higher to lower levels result in longer keystroke intervals, when words or their spelling could not be retrieved in time. The slowdown for these hesitant transitions is captured by $\delta$ in the first line of equation \ref{eq:bimodcon}. The magnitude of the slowdown is associated with transition location. This is because delays at larger linguistic units are likely to be associated with higher level planning.  By constraining $\delta$ to be positive, it captures how much longer hesitant IKIs in addition to $\beta$. 


\begin{equation}
\begin{aligned}
(\#eq:bimodcon)
\text{iki}_{i} \sim\text{ } & \theta_\text{location[i], participant[i]} \cdot \text{log}\mathcal{N}(\beta + \delta_\text{location[i]} + u_\text{participant[i]}, \sigma_{e'_\text{location[i]}}^2) + \\
  & (1 - \theta_\text{location[i], participant[i]}) \cdot \text{log}\mathcal{N}(\beta + u_\text{participant[i]}, \sigma_{e_\text{location[i]}}^2)\\
\text{where: } & u_\text{participant[i]} \sim \mathcal{N}(0, \sigma_\text{p}^2) \\
\text{constraint: } & \delta, \sigma_{e}^2, \sigma_\text{e'}^2, \sigma_\text{p}^2>0\\
		& \sigma_{e'}^2 > \sigma_{e}^2\\
		& 0 < \theta < 1
\end{aligned}
\end{equation}


The first line of equation \ref{eq:bimodcon} represents the distribution of hesitant key transitions, and the second line represents fluent key transitions. Each of these two distributions is associated with the mixing weight $\theta$ which is a proportion that is constrained to be larger than 0 and smaller than 1. $\theta$ is here parameterised to represent the probability that an IKI is associated with the distribution of long IKIs. This probability is inversely related to the mixing weight of the distribution of short IKIs by $1-\theta$ . In other words, a larger weight of one distribution inevitably means a lower weight for the other distribution. The weights of both distributions must sum to 1. We will call this parameter the probability of hesitant transitions.

The probability of hesitant transitions is assumed to vary as a function of both transition location and participants. In line with the literature discussed in the introduction, we assume that pauses are more likely at larger linguistic edges. As pausing is subject to individual differences and writing style (skills), we also assume that some participants pause more at certain transition locations and other participants pause less. This is akin to what is known as a random by-participant slopes model. 

Lastly, we carried over the unequal variance assumption and let the standard deviations $\sigma_{e'}^2$ and $\sigma_{e}^2$ vary by transition location. In addition we constrained the variances so that $\sigma_{e'}$ associated with the distribution of typing disfluencies is larger than the variance associated with fluent transitions $\sigma_e$ [see @vasishth2017; @vasishth2017feature]. This was achieved by introducing a parameter $\sigma_\text{diff}$. The consequence is that fluent transitions are assumed to come from a narrower distribution than hesitant transitions.



### Two-distributions log-Gaussian mixture model (unconstrained)

The size of a fluent key-transition does not necessarily vary by transition location. In other words, the parameter $\beta$ is the same for before-sentence, before-word, and within-word transitions. This is what we called a constrained model. However, letter bigrams and trigrams may be systematically executed faster than transitions between between space and a letter (REFERENCE?) or complex keystrokes that comprise space and shift-letter combinations for upper case characters before sentences (we will address the latter possibility in the results section). This is because bigrams / trigrams might be stored, retrieved and executed as motor codes but not transitions to a space following a word or between a space or shift key press preceding a letter. Also, because of the necessarily larger number of within-word transitions, as opposed to before-word and sentence transitions, the posterior of the constrained model is dominated by within-word transition data. We therefore also implemented an unconstrained model that assumes that the size of fluent transitions varies across transition locations.

In this model we assume that $\beta$ varies by transition-location as illustrated in equation \ref{eq:bimoduncon}.

\begin{equation}
\begin{aligned}
(\#eq:bimoduncon)
\text{iki}_{i} \sim\text{ } & \theta_\text{location[i], participant[i]} \cdot \text{log}\mathcal{N}(\beta_\text{location[i]} + \delta_\text{location[i]} + u_\text{participant[i]}, \sigma_{e'_\text{location[i]}}^2) + \\
  & (1 - \theta_\text{location[i], participant[i]}) \cdot \text{log}\mathcal{N}(\beta_\text{location[i]} + u_\text{participant[i]}, \sigma_{e_\text{location[i]}}^2)\\
	\text{where: }  & u_\text{participant[i]} \sim \mathcal{N}(0, \sigma_\text{p}^2) \\
\text{constraint: } & \delta, \sigma_{e}^2, \sigma_\text{e'}^2, \sigma_\text{p}^2>0\\
		& \sigma_{e'}^2 > \sigma_{e}^2\\
		& 0 < \theta < 1
\end{aligned}
\end{equation}


