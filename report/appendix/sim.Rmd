# Simulation

A possible concern with our results -- the substantially better predictive performance for two-distribution mixture models -- is that, in principle, as the mixture model has more parameters it might always outperform single-distribution models. We addressed this concern before by using cross-validation techniques for model comparison which prevent overfit by penalising models with more parameters. To further address this concern we evaluated models -- similar to the ones used in the main text -- for two sets of simulated data. Data were simulated using two random number generators, one that samples data from a single distribution and another that samples data from a weighted combination of two distributions. These simulated datasets allow us to test the predictive performance of our models in a context where we know the true underlying data generating process.

The first dataset was simulated from a weighted mixture of two log-normal distributions similar to the process described above (equation \ref{eq:bimodcon}). This process and the corresponding Bayesian model that we used to parameter estimation is summarised in equation \ref{eq:simmog}.

\begin{equation}
\begin{aligned}
(\#eq:simmog)
\text{y} \sim\text{ } & \theta \times \log\mathcal{N}(\beta + \delta, \sigma^2_1) +\\
& (1 - \theta) \times \log\mathcal{N}(\beta, \sigma^2_2)\\
\text{constraint: } & \delta, \sigma_\text{2}^2, \sigma_\text{1}^2>0\\
		& \sigma_{1}^2 > \sigma_{2}^2
\end{aligned}
\end{equation}

The equivalent Bayesian model is largely identical to the model used in the main text but does not assume different parameters for transition locations and does not include random effects for participants. This is because we neither simulated data for different transition locations (or other factors) or repeated measures for participants. The model assumes two data generating processes with each assuming a log-normal distribution with a mixing proportion $\theta$. The distribution of smaller values has a mean $\beta$ and a standard deviation $\sigma^2_2$; the second distribution of larger values is constrained to have a mean that is $\delta$ units larger than $\beta$ and has a standard deviation $\sigma^2_1$ larger than the distribution with the central tendency $\beta$.

In R we can simulate data for equation \ref{eq:simmog} using the helper function below.

```{r eval = F, echo = T}
# Function for a mixture of two log-Gaussians
molg <- function(n, theta, mu1, mu2, sigma1, sigma2) {
  y0 <- rlnorm(n, mean = mu1, sd = sigma1)
  y1 <- rlnorm(n, mean = mu2, sd = sigma2)
  mix <- rbinom(n, size = 1, prob = theta)
  y <- y0 * (1 - mix) + y1 * mix 
}

N <- 1000 # number of participants
beta <- 5 # mean of fluent interkey intervals (in log)
delta <- 1 # increment for hesitant interkey intervals (in log)
theta <- .35 # proportion of hesitations
sigma <- c(.25, .5) # error variance

# Simulate data from a mixture of two log-Gaussians
y <- molg(n = N, 
          theta = theta,
          mu1 = beta,
          mu2 = beta + delta,
          sigma1 = sigma[1],
          sigma2 = sigma[2])

```


A second dataset was simulated coming from a single log-normal distribution following equation \ref{eq:simuv}. An equivalent Bayesian model was implemented for parameter estimation.


\begin{equation}
\begin{aligned}
(\#eq:simuv)
\text{y} \sim\text{ }& \log\mathcal{N}(\beta, \sigma^2)\\
\text{constraint: } & \sigma^2>0
\end{aligned}
\end{equation}

Data following the distribution in equation \ref{eq:simuv} can be simulated using the following R code:

```{r echo = T, eval=F}
N <- 1000 # number of participants
beta <- 5 # population mean
sigma <- .25 # error variance

# Simulate data from a single log-normal distribution
y <- rlnorm(n = N, mean = beta, sd = sigma)
```


Again, the Bayesian model corresponding to this process is a simplified version of the single-distribution model used in the main text. The model assumes a log-Gaussian distribution with a mean $\beta$ and a standard deviation $\sigma^2$.

Both simulated datasets are visualised in Figure \ref{fig:simdata}. The parameter values used for each of the two data simulations can be seen in Table \ref{tab:simparam}. Parameter values were chosen so that the simulated data are distributed roughly similar to interkey interval data.

```{r simdata, fig.cap= "Data simulated with a two-distribution (yellow) and a single-distribution (grey) random data-generating process. The x-axis showing the outcome y was log-scaled for visibility.", fig.height=3.5, fig.width=5}
files <- list.files("../../mixture-model-sim/data", full.names = T)

map_dfr(files, ~read_csv(.) %>% 
        mutate(Dataset = str_remove_all(.x, "\\../|/|mixture-model-sim/data|/|\\.|csv"))) %>%
  mutate(across(Dataset, ~recode(., mogdata = "two distributions", lmdata = "single distribution"))) %>% 
  ggplot(aes(x = value, colour = Dataset, fill = Dataset)) +
  geom_density(alpha = .25, 
               linewidth = .25) +
  scale_colour_colorblind() + 
  scale_fill_colorblind() +
  scale_x_log10(labels = ~format(., big.mark = ",")) +
  theme(text = element_text(size = 10)) +
  labs(colour = "Data process", 
       fill = "Data process", 
       x = "y", 
       y = "Density")
```

For each of these two datasets we simulated 1,000 observations. We fitted 2 models -- the two-distribution mixture model and the single-distribution model described above -- for each dataset. Models were run with 3 chains, with each 6,000 iterations of which 3,000 iterations were discarded as warmup samples. Estimates with 95% probability intervals are shown in Table \ref{tab:simparam}. True and estimated parameter values are shown for each data generating process and Bayesian model. Both models successfully uncovered the model parameters for the datasets simulated with the corresponding underlying process, but less so when the model was applied to the data generated with the other incorrect underlying process. 


```{r}
mog1 <- read_csv("../../mixture-model-sim/stanout/mog_mogdata.csv") %>% 
  mutate(data = "mog")
mog2 <- read_csv("../../mixture-model-sim/stanout/mog_lmdata.csv") %>% 
  mutate(data = "lm")
lm1 <- read_csv("../../mixture-model-sim/stanout/lm_lmdata.csv") %>% 
  mutate(data = "lm")
lm2 <- read_csv("../../mixture-model-sim/stanout/lm_mogdata.csv") %>% 
  mutate(data = "mog")

mog_sim <- bind_rows(mog1, mog2) %>% 
  summarise(across(value, list(est = mean,
                               lo = lower,
                               up = upper),
                   .names = "{.fn}"),
            .by = c(name, data)) %>% 
  mutate(across(where(is.numeric), ~round(., 2)),
         across(where(is.numeric), ~ifelse(str_detect(name, "prob"), dezero(., 2), .)),
         across(est, ~str_c(., " [", lo, ", ", up, "]")),
         across(name, ~str_c("\\", .)),
         across(name, ~str_replace(., "a_e", "a^2_1")),
         across(name, ~str_replace(., "ap_e", "a^2_2"))) %>%
  select(-lo, -up) %>% 
  pivot_wider(names_from = data, values_from = est) %>% 
  mutate(true = c(5, 1, .35, .25, .5),
         across(true, ~ifelse(str_detect(name, "prob"), dezero(., 2), .)),
         across(name, ~str_replace(., "prob", "theta"))) %>% 
  relocate(name, true) %>% 
  unite("name", name:true, sep = " = ")

lm_sim <- bind_rows(lm1, lm2) %>% 
  summarise(across(value, list(est = mean,
                               lo = lower,
                               up = upper),
                   .names = "{.fn}"),
            .by = c(name, data)) %>% 
  mutate(across(where(is.numeric), ~round(., 2)),
         across(est, ~str_c(., " [", lo, ", ", up, "]")),
         across(name, ~str_c("\\", .)),
         across(name, ~str_replace(., "a_e", "a^2_1")),
         across(name, ~str_replace(., "ap_e", "a^2_2"))) %>% 
  select(-lo, -up) %>%
  pivot_wider(names_from = data, values_from = est) %>% 
  mutate(true = as.character(c(5, .25))) %>% 
  relocate(name, true) %>% 
  unite("name", name:true, sep = " = ")

```




```{r simparam, results='asis'}
table <- bind_rows(mog_sim %>% mutate(model = "mog"),
                   lm_sim %>% mutate(model = "lm")) %>% 
  relocate(model) %>% 
  mutate(across(name, ~str_c("$", ., "$")))

names(table) <- c("Model", "Parameter with true value", "Two-distribution data", "Single-distribution data")

apa_table(table[,-1], 
          escape = FALSE,
      col_spanners = list("Estimates with 95\\% PIs" = 2:3),
      caption = "Uncovered parameter estimates with 95\\% probability intervals (PI) and true parameter values for each simulated dataset by model.",
      align = c("l", rep("r", 2)),
      stub_indents = list(`Two-distribution model` = 1:5, 
                          `Single-distribution model` = 6:7))


```

We used leave-one-out cross-validation to compare the predictive performance of the two models for each data-generating process. Model comparisons can be found in Table \ref{tab:loossim}. For the data generated with a two-distribution mixture process, the mixture model shows a substantially higher predictive performance. In fact, the mixture model's predictive performance is 11.6 standard errors higher compared to the single-distribution model. However, the mixture model showed a slightly lower predictive performance (i.e. a difference of 0.77 standard errors) for the single-process data. Thus, the single distribution model is the more parsimonious choice for the single-distribution data. These results rule out the possibility that mixture models always lead to higher predictive performance. 


```{r loossim, results='asis'}
table <- read_csv("../../mixture-model-sim/stanout/modelcomparison.csv") %>% 
  select(1:6) %>% 
  mutate(
#    elpd_se_ratio = abs(elpd_diff / se_diff),
    across(ends_with("diff"), ~round(., 1)),
    across(ends_with("loo"), ~round(., 0)),
    across(where(is.numeric), ~format(., big.mark = ",")),
    across(everything(), ~as.character(.)),
    across(everything(), ~str_trim(.)),
    across(everything(), ~str_replace_all(., "NaN", "--")),
    across(elpd_diff, ~str_c(., " (", se_diff, ")")),
    across(elpd_loo, ~str_c(., " (", se_elpd_loo, ")")),
    across(elpd_diff, ~str_replace_all(., "0.0 \\(0.0\\)", "--")),
    across(c(data, model), ~recode(., mog = "Two-distribution mixture model",
                                      lm = "Single-distribution model"))) %>% 
  select(data, model, starts_with("elpd")) 

names(table) <- c("Data", "Model", "$\\Delta\\widehat{elpd}$", "$\\widehat{elpd}$")

apa_table(table[,-1], 
          escape = FALSE,
      caption ="Model comparisons by dataset. The top row shows the models with the highest predictive performance for each data generating process. Standard error is shown in parentheses.",
     note = "$\\widehat{elpd}$ = predictive performance indicated as expected log pointwise predictive density; $\\Delta\\widehat{elpd}$ = difference in predictive performance relative to the model with the highest predictive performance in the top row.",
      align =c("l", rep("r", 2)),
      stub_indents = list(`Data: Two-distribution mixture process` = 1:2, 
                          `Data: Single-distribution process` = 3:4))



```
