---
title             : "Modelling writing hesitations in text writing as finite mixture process"
shorttitle        : "Modelling writing hesitations"

csl               : "apa.csl" 

author: 
  - name          : "Jens Roeser"
    affiliation   : "1"
    address       : "50 Shakespeare St, Nottingham NG1 4FQ"
    corresponding : yes 
    email         : "jens.roeser@ntu.ac.uk"
  - name          : "Mark Torrance"
    affiliation   : "1"
  - name          : "Rianne Conijn"
    affiliation   : "2"
  - name          : "Evgeny Chukharev-Hudilainen"
    affiliation   : "3"

affiliation:
  - id            : "1"
    institution   : "Department of Psychology, Nottingham Trent University, United Kingdom"

  - id            : "2"
    institution   : "Artificial Intelligence Systems Institute, Eindhoven University of Technology, The Netherlands"

  - id            : "3"
    institution   : "Department of English, Iowa State University, Iowa"


abstract: |


keywords: "Keystroke modelling; finite mixture models; Bayesian models; text composition"


bibliography      : ["references.bib"]


documentclass     : "apa7"
classoption       : "man"
output            : 
  papaja::apa6_pdf:
    keep_tex: TRUE

figsintext        : yes
figurelist        : no
tablelist         : no
footnotelist      : no
lineno            : no
mask              : no
csquotes          : true


header-includes:
  - \usepackage{booktabs}
  - \usepackage{longtable}
  - \usepackage{graphicx}
  - \usepackage{array}
  - \usepackage{multirow}
  - \usepackage{float}
  - \usepackage{colortbl}
  - \usepackage{threeparttable}
  - \usepackage[normalem]{ulem}
  - \usepackage[utf8]{inputenc}
  - \usepackage{icomma}
  - \usepackage{pdflscape}
  - \newcommand{\blandscape}{\begin{landscape}}
  - \newcommand{\elandscape}{\end{landscape}}
---

```{r packages, include=FALSE}
library(tidyverse)
library(kableExtra)
library(janitor)
library(brms)
library(polspline)
library(patchwork)
library(rmdformats)
library(gridExtra)
library(grid)
library(gtable)
library(scales)
library(ggthemes)
source("../scripts/functions.R")
source("scripts/get_pdens_plot.R")

theme_set(theme_few(base_size = 9) +
            theme(strip.background = element_blank(),
                  legend.position = "top",
                  legend.justification = "right",
                  panel.grid = element_blank(),
                  panel.background = element_rect(fill = "transparent"), # bg of the panel
                  plot.background = element_rect(fill = "transparent", color = NA)))

options(scipen = 999)

beta_label <- "Short key transition\nduration"
delta_label <- "Slowdown for hesitant key\ntransitions"
theta_label <- "Probability of hesitant\ntransitions"


```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, 
                      warning = FALSE, 
                      message = FALSE, 
                      comment = NA,
                      cache.extra = R.version,
                      dev = "cairo_pdf",
                      fig.align = 'center', 
                      fig.width = 8, 
                      fig.height = 5,
                      width=90)

options(kableExtra.auto_format = FALSE)
dev.args <- list(pdf = list(type = "cairo"))
```


# Introduction

# Methods

## Statistical models

The models presented in the following can be divided into two general groups. The first three models are largely akin to models typically used in the literature. By this we mean models that assume a uni-modal process that generates keystroke data as is incorporated in statistical models such as analysis of variance and linear mixed-effects models. Second, the last two models model keystroke intervals as a combination of two weighted processes of which one presents a smooth information flow from mind into finger; the other component is more important as it represents moments at which the information flow was interrupted leading to longer latencies. The latter two models map directly on the idea of a cascading model of writing.

### Uni-modal Gaussian

We start with a Gaussian mixed-effects models similar to a standard analysis of variance. We describe the process that generates each iki $i$ as normal Gaussian distribution $\text{N}()$ characterised by a mean $\mu$ and a standard deviation $\sigma_\text{e}^2$. The mean can be decomposed into $\beta$ and $\text{participant}_i$. $\beta$ will be allowed to take on a different value for each transition location. Average participant-ikis are allowed to deviate from the average which is achieved by assuming a normal distribution for participant deviations distributed around 0 with a standard deviation $\sigma_\text{p}^2$.

$$
\begin{align}(\#eq:unimodgaus)
\text{iki}_i & \sim \text{N}(\mu_i, \sigma_\text{e}^2)\\
\text{where: } & \mu_i = \beta_\text{location[i]} + \text{participant}_i\\
& \text{participant} \sim \text{N}(0, \sigma_\text{p}^2) 
\end{align}
$$

### Uni-modal log-Gaussian

This model is largely identical to the previous model, except we use a log-normal distribution instead of a normal distribution. The advantage of using a log-normal distribution is two-fold: (1) the log-normal distribution has a lower bound of zero. For our data we generally consider negative ikis as mistakes which occasionally occur when the next key was pressed before the current key. Other than that keystroke intervals are constrained by a persons ability to move their fingers and keyboard polling. (2) the log-scale is known to be a better match for data from human behaviour, in particular motor responses. In particular, a normal distribution assumes that units are linearly scaled. For example, a 50 msecs difference is the same between 100 msecs and 150 msecs than it is between 5 secs and 5 secs 50 msecs (i.e. 5,050 msecs). This is not necessarily plausible for keystroke data. We would assume that differences that are due to motor activity (typing a high frequency bigram vs a low frequency bigram) are smaller than difference that are due to high levels of cognitive activity (retrieving a word in your L1 or L2). Log-normal distributions are a natural way of scaling units so that a 50 msecs difference on the lower end of the iki scale (motor activity) is more meaningful than a 50 msecs difference on the upper end of the iki scale (retrieving words, planning sentences).

The model can be described like this:

$$
\begin{align}(\#eq:unimodloggaus)
\text{iki}_i & \sim \text{logN}(\mu_i, \sigma_\text{e}^2) \\
\text{where: } &
\mu_i = \beta_\text{location[i]} + \text{participant}_i\\
& \text{participant} \sim \text{N}(0, \sigma_\text{p}^2) 
\end{align}
$$

### Uni-modal unequal-variance log-Gaussian

$$
\begin{align}(\#eq:unimoduv)
\text{iki}_i & \sim \text{logN}(\mu_i, \sigma_{e_\text{location[i]}}^2) \\
\text{where: } & \mu_i = \beta_\text{location[i]} + \text{participant}_i\\
 & \text{participant} \sim \text{N}(0, \sigma_\text{p}^2) 
\end{align}
$$


### Bi-modal log-Gaussian (constrained)

This models extends the intuition from the previous model that higher levels of activation lead to longer pauses. Instead of assuming that there is one process that underlies the generation of ikis, we assume there are two. (1) activation can flow into keystrokes without interrupts. These fluent keystroke transitions are merely limited by a person's ability to move their finger and will be captured but the parameter $\beta$. In principle, there are no differences for fluent key-transitions between transition location. The next model with loosen this assumption (hence, "unconstrained model"). (2) difficulty in the activation flow leads to pauses when fingers have to catch-up with cognitive activity, when spelling, words, or contents couldn't be retrieved in time. The size of these pauses will depend on the reason for delays which is typically associated with transition locations (contents are typically planned before sentences, words are retrieved before they are typed and spelling difficulty typically occurs when typing a word). Pauses will be captured by two model parameters: (1) the slowdown for these hesitant transitions will be captured by $\delta$ which is the deviation compared to normal typing intervals (constrained to be positive). (2) the frequency of hesitant transitions will be captured by $\theta$ for each level of a categorical predictor. 

$$
\begin{align}(\#eq:bimodcon)
\text{iki}_{i} & \sim \theta_\text{location[i]} \cdot \text{LogN}(\beta + \delta_\text{location[i]} + \text{participant}_i, \sigma_{e'_\text{location[i]}}^2) + \\
  & (1 - \theta_\text{location[i]}) \cdot \text{LogN}(\beta + \text{participant}_i, \sigma_{e_\text{location[i]}}^2)\\
\text{where: }
		&\delta \sim \text{N}(0,1)\\
 	 & \text{participant} \sim \text{N}(0, \sigma_\text{p}^2) \\
\text{constraint: } & \delta > 0\\
		& \sigma_{e'}^2 > \sigma_{e}^2
\end{align}
$$
This models takes into account two source = s of participant-specific error: (1) each participant has an individual fluent typing as in the previous models; (2) each participant has in individual hesitation frequency that differs across levels of the categorical predictor.


### Bi-modal log-Gaussian (unconstrained)

This model is identical to the previous model with one exception. The distribution of fluent keystroke transitions captured by $\beta$ was fixed to be the same across transition locations is the previous model. In other words, the mean $\beta$ and it's standard deviation $\sigma_{e}^2$ was the same for before-sentence, before-word, and within-word transitions. This means, because of the naturally larger number of within-word transitions, the posterior is dominated by within-word transitions. 

In this model we will loosen this constraint and allow $\beta$ and $\sigma_{e}^2$ to vary by transition-location.

$$
\begin{align}(\#eq:bimoduncon)
\text{iki}_{i} &\sim \theta_\text{location[i]} \cdot \text{LogN}(\beta_\text{location[i]} + \delta_\text{location[i]} + \text{participant}_i, \sigma_{e'_\text{location[i]}}^2) + \\
  & (1 - \theta_\text{location[i]}) \cdot \text{LogN}(\beta_\text{location[i]} + \text{participant}_i, \sigma_{e_\text{location[i]}}^2)\\
	\text{where: } & \delta \sim \text{N}(0,1)\\
	 	 & \text{participant} \sim \text{N}(0, \sigma_\text{p}^2) \\
\text{constraint: } & \delta > 0\\
		& \sigma_{e'}^2 > \sigma_{e}^2
\end{align}
$$


## Data sets

Five datasets with keystroke data from text production were used for analysis. An overview can be found in Table \@ref(tab:datasets).


```{r datasets, results='asis'}
tibble(Dataset = c("C2L1", "CATO", "SPL2", "PLanTra", "LIFT", "GUNNEXP2"),
                Source = c("@ronneberg2022process",
                              "@torrance2016adolescent",
                              "@torrance",
                              "@rossetti2022s",
                              "@nina_vandermeulen_2020_3893538", 
                           ""),
                Keylogger = c("EyeWrite", 
                           "EyeWrite", 
                           "CyWrite", 
                           "InputLog", 
                           "InputLog",
                           "EyeWrite"),
                `Writing task` = c(
                                 "Argumentative essays", 
                                 "Expository texts",
                                 "Argumentative essays",
                                 "Text simplification",
                                 "Synthesis", 
                                 ""),
                 `N (ppts)` = c(126, 26*2, 39, 47, 658, 45),
#                n_texts = c(1, 2, 2, 2, NA),
#                n_sentences = c(),
#                n_words = c(),
                conditions = c(" ", 
                               "weak decoders / control; masked / unmasked",
                               "write in L1 / L2",
                               "pre / post test trained in plain language principles and control", 
                               "Various topics and genres",
                               "masked / unmasked"),
                `Mean age` = c(11.8, 16.9, 20.6, 23, 16.95, NA),
                 Language = c( "Norwegian", 
                               "Norwegian", 
                               "English (L1) / Spanish (L2)", 
                               "English (L2)", 
                               "Dutch",
                               "Norwegian")) %>% 
  kable(caption = "Datasets in brief.") %>%
  kable_styling(position = "center", 
                full_width = T, 
                font_size = 12) 

```

### GUNNEXP2


### C2L1

The C2L1 data set comprises data Norwegian 6th graders -- *N*=126, mean age 11 years 10 months -- published in @ronneberg2022process. The children composed argumentative essays in Norwegian, a language with a relatively shallow orthography.

TODO: might need to remove kids that don't speak Norwegian at home (see github issue).



### CATO

Data are published in @torrance2016adolescent. Norwegian upper
secondary students--*N*=26, mean age = 16.9 years--with weak decoding skills and 26 age-matched controls composed expository texts by keyboard under two conditions: normally and with letters masked to prevent them reading what they were writing. 

### PLanTra

The PLanTra (Plain Language for Financial Content: Assessing the Impact of Training on Students' Revisions and Readers' Comprehension) data set [@rossetti2022s] involved the collection of keystroke data from 47 university students, who were randomly divided into an experimental and a control group. In a pre-test session, all students were assigned an extract of a corporate report dealing with sustainability and were instructed to revise it to make it easier to read for a lay audience. Subsequently, the experimental group received training on how to apply plain language principles to sustainability content, while the control group received training exclusively on the topic of sustainability. During a post-test session, both groups were instructed to revise a second extract of a corporate sustainability report with the same goal--i.e. making it easier to read for a lay audience--by applying what they had learned from their respective training. The texts were in English while the participants were native speakers of other languages (mainly Dutch), so writing took place in second language. It should be pointed out that, while some students decided to revise the assigned texts, the majority of them opted for rewriting the texts from scratch.




### LIFT

LIFT (Improving Pre-university Students' Performance in Academic Synthesis Tasks with Level-up Instructions and Feedback Tool) [@nina_vandermeulen_2020_3893538].



### SPL2

Data are going to be published in @torrance.

Undergraduate university students--*N* = 39, 28 female, mean age = 20.6 years (SD = 1.51)--wrote two short argumentative essays, one in English (the student's first language in all cases; L1) and one in Spanish (L2) using CyWrite [@chukharev2019combined]. CyWrite provides a writing environment with basic word processing functionality (e.g., Microsoft WordPad), including text selection by mouse action, and copy-and-paste. We recorded the time of each keystroke and mouse action, and tracked writers' eye movements within their emerging text.

Writing tasks: Participants were given a 40 minute time limit. They wrote essays in response to each of two prompts, with order and L1 / L2 counterbalanced across subjects.



## Data analysis

### Transition types

The transition types that were analysed in this study focuses on those locations that were found, by previous research, to be psycholinguistically meaningful [e.g. @torrance; @chukharev2019combined; @torrance2016adolescent; @de2018exploring] and are detailed in Table \@ref(tab:keyloc). Keytransitions that terminated in an editing operation were excluded from the analysis. Transitions that occurred at the beginning of the text or the beginning of a paragraph were not treated as before-sentence transitions.

```{r keyloc, results='asis'}
tibble(`Transition type` = c("Within word", "Below word", "Before sentence"),
       Description = c("Transitions between any letter",
                       "Keypress after space followed by any letter",
                       "Keypress following a space preceding any letter"),
       Example = c("T\\^h\\^e c\\^a\\^t m\\^e\\^o\\^w\\^e\\^d. T\\^h\\^a\\^t[bsp][bsp]e\\^n i\\^t s\\^l\\^e\\^p\\^t.", 
                   "The \\^cat \\^meowed. That[bsp][bsp]en \\^it \\^slept.", 
                   "The cat meowed. \\^That[bsp][bsp]en it slept.")) %>% 
  kable(caption = "Transition location classification.") %>%
  footnote("'\\^' marks transition location, [bsp] represents backspace. IKIs were timed to the shift keypress.") %>% 
  kable_styling(position = "center", 
                full_width = T, 
                font_size = 12) 

```




### Data reduction

```{r reductionfunctions}
source("scripts/get_data_summary.R")
```


```{r}
# Get info about data reduction
n_samples <- 100
c2l1 <- get_c2l1("../data/c2l1.csv", n_samples = n_samples)
cato <- get_cato("../data/cato.csv", n_samples = n_samples)
lift <- get_lift("../data/lift.csv", n_samples = 50, n_ppts = 100)
plantra <- get_plantra("../data/plantra.csv", n_samples = n_samples)
spl2 <- get_spl2("../data/spl2.csv", n_samples = n_samples) 
gunnexp2 <- get_gunnexp2("../data/gunnexp2.csv", n_samples = n_samples)
```


For all datasets we only used transitions that were not followed by an editing operation.

We removed participants that did not complete all conditions in studies with within-participant factors (reducing the number of participants to 343 in the LIFT data set, and 41 participants in the PLanTra data set). We removed participants that produced less than 10 sentences (LIFT: 109 participants; PLanTra: 3 participants; SPL2: 1 participant)

We removed keystroke intervals that are extremely short ($\le$ 50 msecs) or extremely long ($\ge$ 30 secs). The percentage of remove keystroke data can be found in Table \@ref(tab:datareduction).

From the remaining data we randomly sampled `r n_samples` observations per participant, per condition, and per transition location, with the exception of the LIFT data set. This was done for computational reasons to reduce the time the Bayesian models need to complete. For the LIFT data set we reduced the number of participants to 100 which is substantially more than most of the other data sets in our analysis. Because we included the large number of writing tasks in the LIFT data set as fixed effect, we sampled 50 observations per condition, location and participant. The percentage of keystroke data that went into the final analysis can be found, by transition location, in Table \@ref(tab:datareduction).


```{r datareduction, results='asis'}
c2l1$ds <- "c2l1"
cato$ds <- "cato"
lift$ds <- "lift"
plantra$ds <- "plantra"
spl2$ds <- "spl2"
gunnexp2$ds <- "gunnexp2"

extrem_values <- map_dfr(list(c2l1, cato, lift, plantra, spl2, gunnexp2), ~.x[[1]] %>% 
          mutate(ds = .x$ds)) %>% 
  mutate(across(where(is.numeric), ~round(.*100, 2)),
         across(starts_with("too"), ~str_c(., "%"))) %>% 
  unite("<50ms", starts_with("too_fast"), sep = " (") %>% 
  unite(">30,000ms", starts_with("too_slow"), sep = " (") %>% 
  mutate(across(c(`<50ms`, `>30,000ms`), ~str_c(., ")"))) %>% 
  rename(`$\\le$ 50 msecs` = `<50ms`,
         `$\\ge$ 30 secs` = `>30,000ms`)
  
random_sample <- 
  map_dfr(list(c2l1, cato, lift, plantra, spl2, gunnexp2), ~.x[[2]] %>% 
          mutate(ds = .x$ds)) %>% 
    mutate(across(where(is.numeric), ~round(.*100, 1)),
           across(starts_with("keep"), ~str_c(., "%"))) %>%
    unite("keep", starts_with("keep"), sep = " (") %>% 
    mutate(across(c(keep), ~str_c(., ")"))) %>%
  pivot_wider(names_from = location, values_from = keep)

datareduction <- left_join(extrem_values, random_sample, by = "ds") %>% 
  relocate(ds) %>% 
  mutate(across(ds, recode, 
                "cato" = "CATO",
                "spl2" = "SPL2", 
                "spl2_shift" = "SPL2 (shift + C)", 
                "plantra" = "PLanTra",
                "lift" = "LIFT",
                "c2l1" = "C2L1",
                "gunnexp2" = "GUNNEXP2")) %>% 
  rename(`Dataset` = ds)

kable(datareduction, 
      caption = "Data reduction. Mean percentage of extreme data removed and the mean percentage of randomly sampled data by transition locattion. Standard error is shown in parentheses.",
        align =c("l", rep("r", 14))) %>%
  kable_styling(position = "center", 
                full_width = T, 
                font_size = 11) %>%
  add_header_above(c(" " = 1, 
                     "Extreme values" = 2,
                     "Randomly sampled data" = 3)) %>%
  column_spec(1, width = "8em")

```



### Bayesian modelling

Keystroke data from text composition tasks were modelled in a series of five models. An overview of all models can be found in Table \ref{tab:models}.


```{r models, results = 'asis'}
models <- tibble(Models = paste0("M",1:4),
       Type = c("LMM", "LMM", "LMM", "MoG", "MoG"),
       Equation = paste0("\ \\ref{eq:", c("unimodgaus", "unimodloggaus", "unimoduv", "bimodcon", "bimoduncon"), "}"),
       Description = c("Gaussian distribution",
                       "Log-normal distribution",
                       "Log-normal distribution and unequal variances",
                       "Fluent transition are not allowed to vary by transition location",
                       "Fluent transition are allowed to vary by transition location")) 

papaja::apa_table(models, align = c("l", "l", "l"), escape = FALSE, digits = 0, placement = "bp!",
                  caption = "Overview of typing-process models. All models were fitted with random intercepts for participants.",
                  note = "LMM = Unimodal mixed-effects models; MoG = bimodal mixture of log-Gaussians") 
```




each with random effects for participants. Probability functions used were normal and log-normal in line with typically treatments used in the literature, a log-normal distribution with unequal variances for model predictions, and a bimodal mixed effects model. Stan code for mixture models was based on @roeser2021modelling. Text locations (levels: before sentence, before word, within word) was included as predictor in all models.


Data were analysed in Bayesian mixed effects models [@gelman2014;@mcelreath2016statistical]. The R [@R-base] package rstan [@rstan] was used to interface with the probabilistic programming language Stan [@carpenter2016stan] which was used to implement all models. Models were fitted with weakly informative priors [see @mcelreath2016statistical], and run with 20,000 iterations on 3 chains with a warm-up of 10,000 iterations and no thinning. Model convergence was confirmed by the Rubin-Gelman statistic ($\hat{R}$ = 1) [@gelman1992] and inspection of the Markov chain Monte Carlo chains.


# Results

## Out-of-samples cross-validation

For model comparisons we used out-of-sample predictions estimated using Pareto smoothed importance-sampling leave-one-out cross-validation [@vehtari2015pareto; @vehtari2017practical]. Predictive performance was estimated as the sum of the expected log predictive density ($\widehat{elpd}$) and the difference $\Delta\widehat{elpd}$ between models. The advantage of using leave-one-out cross-validation is that models with more parameters are penalised to prevent overfit.

Results for all data sets are shown in Table \@ref(tab:loos). For all data sets we found the same pattern. The mixture of log-normal distributions provided a substantially better fit than uni-modal distribution models. The unconstrained version of the mixture of log-normal distributions rendered a higher predictive performance than the constrained version that does not allow the distribution of short keystroke-intervals to vary across conditions. 



```{r}
files <- list.files(
  str_c("../stanout/", 
  c("lift", "spl2", "spl2_shift", "plantra", "cato", "c2l1", "gunnexp2")), 
  pattern = "model.+.csv", 
  full.names = T)

table <- purrr::map_dfr(files, ~read_csv(.) %>% 
                          mutate(dataset = .x)) %>% 
  select(dataset, model, elpd_diff, se_diff, elpd_loo, se_elpd_loo) %>%
  mutate(across(dataset, ~sub(".*/([^/]+)/[^/]+\\..*", "\\1", .)),
         across(where(is.numeric), round, 0),
         across(where(is.numeric), format, big.mark = ","),
         across(everything(), str_trim)) %>%
  transmute(
     across(dataset, recode, 
                "cato" = "CATO",
                "spl2" = "SPL2", 
                "spl2_shift" = "SPL2 (shift + C)", 
                "plantra" = "PLanTra",
                "lift" = "LIFT",
                "c2l1" = "C2L1",
                "gunnexp2" = "GUNNEXP2"),
    across(model, recode, lmm = "Unimodal log-normal",
                          lmmgaus = "Unimodal normal",
                          mogbetaconstr = "Bimodal log-normal (constrained)",
                          mogbetacontr = "Bimodal log-normal (constrained)",
                          mogbetaunconstr = "Bimodal log-normal (unconstrained)",
                          lmmuneqvar = "Unimodal log-normal (unequal variance)"),
            across(elpd_diff, str_c, " (", se_diff, ")"),
            across(elpd_loo, str_c, " (", se_elpd_loo, ")")) %>% 
  mutate(across(elpd_diff, str_replace, "0 \\(0\\)", "--")) %>% 
  pivot_wider(names_from = dataset, values_from = contains("elpd")) %>% 
  select(Model = model, ends_with("GUNNEXP2"), ends_with("CATO"), ends_with("C2L1"), ends_with("LIFT"), ends_with("PLanTra"), ends_with("SPL2"), ends_with("+ C)"))

```


```{r loos, results='asis'}
names(table)[-1] <- rep(c("$\\Delta\\widehat{elpd}$", "$\\widehat{elpd}$"), 8)

kable(table, 
      caption = "Model comparisons. The top row shows the models with the highest predictive performance. Standard error is shown in parentheses.",
        align =c("l", rep("r", 14))) %>%
  kable_styling(position = "center", 
                full_width = T, 
                font_size = 11) %>%
  footnote("$\\widehat{elpd}$ = predictive performance indicated as expected log pointwise predictive density; $\\Delta\\widehat{elpd}$ = difference in predictive performance relative to the model with the highest predictive performance in the top row.") %>%
  add_header_above(c(" " = 1, 
                     "GUNNEXP2" = 2,
                     "CATO" = 2,
                     "CL21" = 2, 
                     "LIFT" = 2,
                     "PLanTra" = 2,
                     "SPL2" = 2,
                     "SPL2 (shift + C)" = 2)) %>%
  column_spec(1, width = "8em")

```


## Cross-data set comparisons

```{r}
# Get the differences for tasks / across data set
# use effect size = beta / sd
# averaged across grouping variable



```




```{r}
files <- list.files(str_c("../stanout/", 
                          c("lift", "spl2", "plantra", "cato", "c2l1", "gunnexp2")), 
                    pattern = "mogbetaun.+.csv", 
                    full.names = T)

ps <- purrr::map_dfr(files, ~read_csv(.x) %>% 
  mutate(data = .x)) %>% 
  mutate(across(data, ~sub(".*/([^/]+)/[^/]+\\..*", "\\1", .)),
         across(data, recode_factor, 
                "cato" = "CATO (non-dyslexic\nunmasked)",
                "gunnexp2" = "GUNNEXP2 (unmasked)",
                "spl2" = "SPL2 (L1)", 
#                "spl2 (shift + C)" = "SPL2 (L1; shift + C)", 
                "plantra" = "PLanTra",
                "lift" = "LIFT",
                "c2l1" = "C2L1",
                .ordered = TRUE)) %>% 
  filter(!(str_detect(data, "SPL2") & lang == "ES"),
         !(str_detect(data, "CATO") & group == "dyslexic"),
         !(str_detect(data, "CATO") & task == "masked"),
         !(str_detect(data, "GUNNEXP2") & xn == "masked")) %>% 
  pivot_wider(names_from = param, 
              values_from = value) %>% 
  unnest(cols = beta:theta) %>% 
  mutate(across(c(beta, beta2), exp),
         delta = beta2 - beta,
         across(location, str_replace, " ", "\n")) %>% 
  pivot_longer(beta:theta) %>% 
  summarise(across(value, 
                   list(mean = mean, 
                        lower = lower, 
                        upper = upper),
                   .names = "{.fn}"), 
            .by = c(data, location, name)) %>% 
  filter(name %in% c("beta", "delta", "prob"))
```



The model estimates for the mixture-model with the highest predictive performance are shown in Figure \@ref(fig:crossstudypost). In this visualisation we ignore dataset specific conditions that are presented in detail below.

```{r crossstudypost, fig.cap="Across studies. Posterior parameter distribution"}
posd <- position_dodge(.65)
dotsize <- 2.5
grouplabel <- "Data set"
shapes <- c(1, 4, 6, 7, 8, 9, 11)
beta <- filter(ps, name == "beta") %>% 
  mutate(name = beta_label) %>% 
  ggplot(aes(y = mean, 
             ymin = lower, 
             ymax = upper,
             x = location,
             shape = data,
             group = interaction(data))) +
  geom_line(size = .5, 
            alpha = .35, 
            position = posd) +
  geom_errorbar(width = .2, alpha = .75, position = posd) +
  geom_point(aes(colour = data), 
            size = dotsize, 
            position = posd) +
  facet_grid(~name) +
  scale_shape_manual(values = shapes) +
  scale_colour_colorblind() +
  scale_y_log10(labels = scales::comma) +
  labs(y = "Posterior estimate with 95% PIs",
       x = "",
       colour = grouplabel,
       shape = grouplabel) +
  guides(colour=guide_legend(nrow=2,byrow=TRUE),
         shape = guide_legend(nrow=2,byrow=TRUE))

delta <- filter(ps, name == "delta") %>% 
  mutate(name = delta_label) %>% 
  ggplot(aes(y = mean, 
             ymin = lower, 
             ymax = upper,
             x = location,
             shape = data,
             group = interaction(data))) +
  geom_line(size = .5, alpha = .35, position = posd) +
  geom_errorbar(width = .2, alpha = .75, position = posd) +
  geom_point(aes(colour = data), 
            size = dotsize, 
            position = posd) +
  facet_grid(~name) +
  scale_shape_manual(values = shapes) +
  scale_colour_colorblind() +
  scale_y_log10(labels = scales::comma) +
  labs(y = "",
       x = "Transition location",
       colour = grouplabel,
       shape = grouplabel) +
  theme(axis.title.y = element_blank()) +
  guides(colour=guide_legend(nrow=2,byrow=TRUE),
         shape = guide_legend(nrow=2,byrow=TRUE))


theta <- filter(ps, name == "prob") %>% 
  mutate(name = theta_label) %>% 
  ggplot(aes(y = mean, 
             ymin = lower, 
             ymax = upper,
             x = location,
             shape = data,
             group = interaction(data))) +
  geom_line(size = .5, alpha = .35, position = posd) +
  geom_errorbar(width = .2, alpha = .75, position = posd) +
  geom_point(aes(colour = data), 
            size = dotsize, 
            position = posd) +
  facet_grid(~name) +
  scale_shape_manual(values = shapes) +
  scale_colour_colorblind() +
  scale_y_continuous(labels = dezero_plot, limits = c(0, 1)) +
  labs(y = "",
       x = "",
       colour = grouplabel,
       shape = grouplabel) +
  theme(axis.title.y = element_blank()) +
  guides(colour=guide_legend(nrow=2,byrow=TRUE),
         shape = guide_legend(nrow=2,byrow=TRUE))

beta + delta + theta +
  plot_layout(guides = "collect")

```


It's generally agreed that pausing is associated with syntactic edges such that more and longer pauses are predicted for key transitions at larger syntactic edges, i.e. before sentence > before word > within word. We have evaluated the differences between transition locations for all data sets. The results are shown in Table \@ref(tab:loceffect). 

Results are largely consistent across data sets (with caveats) but differ, to some extent, from what the literature would predict. In line with the literature hesitations are more frequent before words than within words. Also hesitations are longer at before-sentence transitions compared to before-word transitions (except dataset C2L1) compared to within-word transitions (except dataset LIFT). However, our results do not support that writers pause more frequently at before-sentence locations compared to before-word locations (except for dataset SPL2; this also shows that more pauses at before-sentence locations can not be explained on the basis of multi-key combinations for sentence-initial capitalisation). Also, we observe that even fluent key-transitions are slower at before-word locations compared to within-word locations but there is generally not difference for fluent transitions for before-sentence transitions compared to before-word transitions (except for dataset SPL2).

The datasets differ to the extent that sentence-initial key transitions do (PLanTra, LIFT) or do not (CATO, C2L1, SPL2) include the character following the shift key for capitalisation. In other words, the pause before sentences may sum across two key intervals, namely `_^[shift]^C` but only involves one keyintervals, namely `_^[shift]`. For the SPL2 dataset, we calculated location effects for sentence-initial transitions that do and do not involve the shift-to-key transition. The results were the same for the transition location effects. A comparison that is untangling the effects of the multi-keycombination on the mixture-model estimates can be found in Table \@ref(tab:shiftcellmeans). In short, the duration of fluent transitions and the hesitation slowdown are affected but not the hesitation probability.


In conclusion, while pauses tend to be longer before sentences they are not more frequent than before words.

```{r loceffect, results='asis'}
files <- list.files(str_c("../stanout/", 
                          c("lift", "spl2", "spl2_shift", "gunnexp2", "plantra", "cato", "c2l1")), 
                    pattern = "mogbetaun.+.csv", 
                    full.names = T)

ps_loc_diffs <- purrr::map_dfr(files, ~read_csv(.x) %>% 
  mutate(data = .x)) %>% 
  mutate(across(data, ~sub(".*/([^/]+)/[^/]+\\..*", "\\1", .)),
         across(data, recode_factor, 
                "cato" = "CATO (non-dyslexic\nunmasked)",
                "spl2" = "SPL2 (L1)", 
                "gunnexp2" = "GUNNEXP2 (unmasked)",
                "spl2_shift" = "SPL2 (L1; shift + C)", 
                "plantra" = "PLanTra",
                "lift" = "LIFT",
                "c2l1" = "C2L1",
                .ordered = TRUE)) %>% 
  filter(!(str_detect(data, "SPL2") & lang == "ES"),
         !(str_detect(data, "CATO") & group == "dyslexic"),
         !(str_detect(data, "CATO") & task == "masked"),
         !(str_detect(data, "GUNNEXP2") & xn == "masked"),
         param %in% c("beta", "delta", "theta")) %>%
  select(param, location, data, value) %>% 
  mutate(across(value, ~ifelse(param == "theta", .*-1, .))) %>% 
  pivot_wider(names_from = location, values_from = value) %>%
  unnest(-c(data, param)) %>% 
  mutate(diff.1 = `before sentence` - `before word`,
         diff.2 = `before word` - `within word`) %>% 
  summarise(across(starts_with("diff"), 
                   list(mean = mean, lower = lower, upper = upper, BF = BF)),
            .by = c(data, param)) 

tmp <- ps_loc_diffs %>% 
  pivot_longer(starts_with("diff"), names_to = c("diffid", ".value"), names_sep = "_") %>% 
  mutate(across(mean, ~pmap_chr(list(., lower, upper, 2), PI)),
         across(BF, ~ifelse(.>100, "> 100", as.character(round(.,2))))) %>% 
  select(-lower, -upper) %>% 
  pivot_wider(names_from = param, values_from = c(mean, BF)) %>% 
  mutate(across(diffid, ~recode(., diff.1 = "before sentence vs word",
                                   diff.2 = "before vs within word"))) %>% 
  select(data, diffid, ends_with("beta"), ends_with("delta"), ends_with("theta"))
  
write_csv(tmp, "tables/location_effect_alldata.csv")


tmp %>% knitr::kable(align =c("l", "l", rep("r", 6)), 
                     col.names = c("Data set", "Difference", rep(c("Est. with 95% PIs", "BF"), 3)),
                     caption = "Effect of transition location on keystroke intervals. Differences between transition locations are shown on log scale (for transition durations) and logit scale for probability of hesitant transitions. 95% PIs in brackets.") %>%
  kableExtra::collapse_rows(columns = 1) %>%
  kable_styling(position = "center", full_width = T, font_size = 11) %>%
  footnote("PIs are probability intervals. BF is the evidence in favour of the alternative hypothesis over the null hypothesis.", threeparttable = T) %>% 
  add_header_above(c(" " = 2, 
                     "Fluent transitions" = 2, 
                     "Slowdown for hesitations" = 2, 
                     "Probability of hesitations" = 2)) %>% 
  column_spec(1, width = "3cm") 

```


## Simulation

A general concern with mixture models is that in principle, as the mixture model has more parameters it might simply always lead to a better fit, even though cross-validation is addressing potential problems with overfitting models.

To address this concern we simulated two sets of data. Both data sets have two conditions and 1,000 observations each. The first set of data has as underlying data generating process a mixture model with two mixture components similar to the process described above. The difference between the two conditions is that the mixing proportion is larger for condition 2 than for condition 1, hence long observations are more likely in condition 2. This model can be summarised as followed:

$$
\begin{align}(\#eq:simmog)
\text{y}_i \sim\text{ } & \theta_\text{condition[i]} \cdot \text{logN}(\mu_1, \sigma^2_1) +\\
& (1 - \theta_\text{condition[i]}) \cdot \text{logN}(\mu_2, \sigma^2_2)
\end{align}
$$

The second data set was generated with an unequal variance unimodal model as data generating process. Condition 2 has a larger mean and standard deviation than condition 1. The model can be summaried as followed:

$$
\begin{align}(\#eq:simuv)
\text{y}_i \sim\text{ }& \text{logN}(\mu_\text{condition[i]}, \sigma^2_\text{condition[i]})
\end{align}
$$

The true parameter values used for each of the two data simulations can be found in Table \@ref(tab:simparam). The simulated data are visualised in Figure \@ref(fig:simdata). The data are simulated to be similarly distributed to keystroke transitions.

```{r simdata, fig.cap= "Data simulated with a bimodal process (left) and a unimodal process (right).", fig.height=4}
files <- list.files("../mixture-model-sim/data", full.names = T)

map_dfr(files, ~read_csv(.) %>% 
          mutate(Dataset = str_remove_all(.x, "../mixture-model-sim/data|/|.csv" ))) %>%
  mutate(across(condition, factor),
         across(condition, ~str_c("Condition: ", condition)),
         across(Dataset, ~recode(., mogdata = "bimodal", uvlmdata = "unimodal"))) %>% 
  ggplot(aes(x = value, colour = condition, fill = condition)) +
  geom_density(alpha = .25) +
  facet_grid(~Dataset, labeller = label_both) +
  scale_colour_colorblind() + 
  scale_fill_colorblind() +
  labs(colour = "", fill = "", x = "Simulated data", y = "Density")
  
```



We run 4 models: 2 mixture models, one on the data generated with a mixture process and one on the data generated with the unimodal unequal variance process. We repeated the same using an unimodal unequal variance model. Models were run with 3 chains, with each 6,000 iterations of which 3,000 were warmup. The Stan models uncovered the model parameters of their respective data sets successfully, as shown in Table \@ref(tab:simparam), not less so when the model was applied to data generated with the other underlying process.

```{r}
mog1 <- read_csv("../mixture-model-sim/stanout/mog_mogdata.csv") %>% 
  mutate(data = "mog")
mog2 <- read_csv("../mixture-model-sim/stanout/mog_uvlmdata.csv") %>% 
  mutate(data = "uvlm")
uvlm1 <- read_csv("../mixture-model-sim/stanout/uvlm_uvlmdata.csv") %>% 
  mutate(data = "uvlm")
uvlm2 <- read_csv("../mixture-model-sim/stanout/uvlm_mogdata.csv") %>% 
  mutate(data = "mog")

mog_sim <- bind_rows(mog1, mog2) %>% 
  summarise(across(value, list(est = mean,
                               lo = lower,
                               up = upper),
                   .names = "{.fn}"),
            .by = c(name, data)) %>% 
  mutate(across(where(is.numeric), round, 2),
         across(where(is.numeric), ~ifelse(str_detect(name, "prob"), dezero(., 2), .)),
         across(est, ~str_c(., " [", lo, ", ", up, "]")),
         across(name, ~str_c("\\", .)),
         across(name, ~str_replace(., "a_e", "a^2_1")),
         across(name, ~str_replace(., "ap_e", "a^2_2")),
         across(name, ~str_replace(., "\\[1\\]", "_\\\\text{condition=1}")),
         across(name, ~str_replace(., "\\[2\\]", "_\\\\text{condition=2}"))) %>%
  select(-lo, -up) %>% 
  pivot_wider(names_from = data, values_from = est) %>% 
  mutate(true = c(5, 1, .1, .4, .25, .5),
         across(true, ~ifelse(str_detect(name, "prob"), dezero(., 2), .)),
         across(name, ~str_replace(., "prob", "theta"))) %>% 
  relocate(name, true)

uvlm_sim <- bind_rows(uvlm1, uvlm2) %>% 
  summarise(across(value, list(est = mean,
                               lo = lower,
                               up = upper),
                   .names = "{.fn}"),
            .by = c(name, data)) %>% 
  mutate(across(where(is.numeric), round, 2),
         across(est, ~str_c(., " [", lo, ", ", up, "]")),
         across(name, ~str_c("\\", .)),
         across(name, ~str_replace(., "a_e", "a^2_1")),
         across(name, ~str_replace(., "ap_e", "a^2_2")),
         across(name, ~str_replace(., "\\[1\\]", "_\\\\text{condition=1}")),
         across(name, ~str_replace(., "\\[2\\]", "_\\\\text{condition=2}"))) %>% 
  select(-lo, -up) %>%
  pivot_wider(names_from = data, values_from = est) %>% 
  mutate(true = as.character(c(5, 6, .25, .5))) %>% 
  relocate(name, true)

```




```{r simparam, results='asis'}
table <- bind_rows(
  mog_sim %>% mutate(model = "mog"),
  uvlm_sim %>% mutate(model = "uvlm")) %>% 
  relocate(model) %>% 
  mutate(across(name, ~str_c("$", ., "$")))

names(table) <- c("Model", "Parameter", "True value", "Bimodal data", "Unimodal data")

kable(table[,-1], 
      caption = "Uncovered parameter estimates with 95% probability interval (PI) and true parameter values for each simulated data set and by model and their respective parameters.",
      align =c("l", rep("r", 3))) %>%
  kable_styling(position = "center", 
                full_width = F, 
                font_size = 11) %>% 
  add_header_above(c(" " = 1, 
                     " " = 1,
                     "Estimate with 95\\% PI" = 2)) %>%
  pack_rows("Model: Bimodal mixture model", 1, 6) %>% 
  pack_rows("Model: Unimodal process", 7, 10)


```

We used LOO-CV to compare the fit of the two models for each data set. The model comparisons can be found for each data generating process in Table \ref@(tab:loossim). The results show that the mixture model does not always lead to higher predictive performance. Indeed, the mixture model showed a lower predictive performance for the data that were generated with a unimodal process. However, for the data generated with a bimodal process, the mixture model model shows a higher predictive performance. In fact, the ratio of $\Delta\widehat{elpd}$ and its SE, as metric for the strength of evidence, shows that the mixture model performs 11 times better than the unimodal model for the data generated with a bimodal process. In comparison, for the unimodal data, the unimodal model shows only 3 times better than the bimodal mixture model. Thus, even though the mixture model does not necessarily perform better for non-bimodal data but it also doesn't necessarily perform much worse. This contrast is likely a reflection of the increased number of parameters in the mixture model. 

```{r loossim, results='asis'}
table <- read_csv("../mixture-model-sim/stanout/modelcomparison.csv") %>% 
  select(1:6) %>% 
  mutate(
#    elpd_se_ratio = abs(elpd_diff / se_diff),
    across(where(is.numeric), round, 0),
    across(where(is.numeric), format, big.mark = ","),
    across(everything(), as.character),
    across(everything(), str_trim),
    across(everything(), str_replace_all, "NaN", "--")) %>% 
  mutate(across(elpd_diff, str_c, " (", se_diff, ")"),
         across(elpd_loo, str_c, " (", se_elpd_loo, ")"),
         across(elpd_diff, str_replace_all, "0 \\( 0\\)", "--"),
         across(c(data, model), ~recode(., mog = "Bimodal mixture model",
                                        uvlm = "Unimodal unequal-variance model"))) %>% 
  select(data, model, starts_with("elpd")) 

names(table) <- c("Data", "Model", "$\\Delta\\widehat{elpd}$", "$\\widehat{elpd}$")

kable(table[,-1], 
      caption = "Model comparisons by data set. The top row shows the models with the highest predictive performance. Standard error is shown in parentheses.",
        align =c("l", rep("r", 2))) %>%
  kable_styling(position = "center", 
                full_width = F, 
                font_size = 11) %>%
  footnote("$\\widehat{elpd}$ = predictive performance indicated as expected log pointwise predictive density; $\\Delta\\widehat{elpd}$ = difference in predictive performance relative to the model with the highest predictive performance in the top row.") %>% 
  pack_rows("Data: Bimodal mixture process", 1, 2) %>% 
  pack_rows("Data: Unimodal process", 3, 4)

```






# Discussion

# References
```{r create_r-references, echo=FALSE, include=FALSE}
r_refs(file = "references.bib")
```

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}
  
<div id = "references"></div>
\endgroup
  
# Appendix

## Fit to data

```{r prediction, fig.cap="Fit to data. Comparison of 100 simulated (predicted) sets of data to observed data illustated by model. For illustration the x-axis was truncated at 2,000 msecs.", eval = T, fig.height=10}

run <- FALSE

if(run){
  file <- list.files("../stanout", pattern = "sims", full.names = T, recursive = T)
  ds <- str_remove_all(file, "\\.|\\/|stanout|all_sims.csv") %>% 
    str_to_upper() %>% 
    str_replace(., "PLANTRA", "PLanTra")
  ds <- ds[-6]
  plots <- list()
  plots <- map(1:length(ds), ~get_pdens_plot(file[.], max_iki = 2000, ds = ds[.])) 
  #plots <- map(1, ~get_pdens_plot(file[.], max_iki = 2000, ds = ds[.])) 
  plots_fin <- plots[[1]] / plots[[2]] / plots[[3]] / plots[[4]] / plots[[5]] / plots[[6]] +
    plot_layout(guides = "collect") &
  #  plot_annotation(tag_levels = 'A') & 
    theme(legend.position = 'bottom')
  saveRDS(plots_fin, "objects/fitplots.rda", compress = "xz")
}

plots <- readRDS("objects/fitplots.rda")
```


## Posterior parameter estimates

