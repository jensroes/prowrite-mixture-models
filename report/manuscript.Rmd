---
title             : "Modelling writing hesitations in text writing as finite mixture process"
shorttitle        : "Modelling writing hesitations"

csl               : "apa.csl" 

author: 
  - name          : "Jens Roeser"
    affiliation   : "1"
    address       : "50 Shakespeare St, Nottingham NG1 4FQ"
    corresponding : yes 
    email         : "jens.roeser@ntu.ac.uk"
  - name          : "Mark Torrance"
    affiliation   : "1"
  - name          : "Rianne Conijn"
    affiliation   : "2"
  - name          : "Evgeny Chukharev-Hudilainen"
    affiliation   : "3"

affiliation:
  - id            : "1"
    institution   : "Department of Psychology, Nottingham Trent University, United Kingdom"

  - id            : "2"
    institution   : "Artificial Intelligence Systems Institute, Eindhoven University of Technology, The Netherlands"

  - id            : "3"
    institution   : "Department of English, Iowa State University, Iowa"


abstract: |


keywords: "Keystroke modelling; finite mixture models; Bayesian models; text composition"


bibliography      : ["references.bib"]


documentclass     : "apa7"
classoption       : "man"
output            : 
  papaja::apa6_pdf:
    keep_tex: TRUE
    includes:
      after_body: 
        - "appendix_a.tex"
        - "appendix_b.tex"
        - "appendix_c.tex"
        - "appendix_d.tex"
        - "appendix_e.tex"
        - "appendix_g.tex"
        - "appendix_f.tex"

figsintext        : yes
figurelist        : no
tablelist         : no
footnotelist      : no
lineno            : no
mask              : no
csquotes          : true


header-includes:
  - \usepackage{booktabs}
  - \usepackage{longtable}
  - \usepackage{graphicx}
  - \usepackage{array}
  - \usepackage{multirow}
  - \usepackage{float}
  - \usepackage{colortbl}
  - \usepackage{threeparttable}
  - \usepackage[normalem]{ulem}
  - \usepackage[utf8]{inputenc}
  - \usepackage{icomma}
  - \usepackage{pdflscape}
  - \newcommand{\blandscape}{\begin{landscape}}
  - \newcommand{\elandscape}{\end{landscape}}
  - \DeclareCaptionFormat{cont}{#1 (cont.)#2#3\par}
---



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, 
                      warning = FALSE, 
                      message = FALSE, 
                      comment = NA,
                      cache.extra = R.version,
                      dev = "cairo_pdf",
                      fig.align = 'center', 
                      fig.width = 8, 
                      fig.height = 5,
                      width=90)

options(kableExtra.auto_format = FALSE)
dev.args <- list(pdf = list(type = "cairo"))
```

```{r libs, include=FALSE}
library(tidyverse)
library(janitor)
library(brms)
library(papaja)
library(polspline)
library(patchwork)
library(gridExtra)
library(grid)
library(gtable)
library(scales)
library(ggthemes)
source("../scripts/functions.R")
source("scripts/get_pdens_plot.R")

theme_set(theme_few(base_size = 12) +
            theme(strip.background = element_blank(),
                  legend.position = "top",
                  legend.justification = "right",
                  panel.grid = element_blank(),
                  panel.background = element_rect(fill = "transparent"), # bg of the panel
                  plot.background = element_rect(fill = "transparent", color = NA)))

options(scipen = 999)

beta_label <- "Short key transition\nduration (in msecs)"
delta_label <- "Slowdown for hesitant key\ntransitions (in secs)"
theta_label <- "Probability of hesitant\ntransitions"
```



# Introduction

# Methods

## Statistical models

The models presented in the following can be divided into two general groups. The first three models are largely akin to models typically used in the literature. By this we mean models that assume a uni-modal process that generates keystroke data as is incorporated in statistical models such as analysis of variance and linear mixed-effects models. Second, the last two models model keystroke intervals as a combination of two weighted processes of which one presents a smooth information flow from mind into finger; the other component is more important as it represents moments at which the information flow was interrupted leading to longer latencies. The latter two models map directly on the idea of a cascading model of writing.

### Unimodal Gaussian

We start with a Gaussian mixed-effects models similar to a standard analysis of variance. We describe the process that generates each iki $i$ as normal Gaussian distribution $\text{N}()$ characterised by a mean $\mu$ and a standard deviation $\sigma_\text{e}^2$. The mean can be decomposed into $\beta$ and $\text{participant}_i$. $\beta$ will be allowed to take on a different value for each transition location. Average participant-ikis are allowed to deviate from the average which is achieved by assuming a normal distribution for participant deviations distributed around 0 with a standard deviation $\sigma_\text{p}^2$.

\begin{equation}
\begin{aligned}
(\#eq:unimodgaus)
\text{iki}_i & \sim \text{N}(\mu_i, \sigma_\text{e}^2)\\
\text{where: } & \mu_i = \beta_\text{location[i]} + \text{participant}_i\\
& \text{participant} \sim \text{N}(0, \sigma_\text{p}^2)\\
\text{constraint: } & \sigma_\text{e}^2, \sigma_\text{p}^2>0
\end{aligned}
\end{equation}

### Unimodal log-Gaussian

This model is largely identical to the previous model, except we use a log-normal distribution instead of a normal distribution. The advantage of using a log-normal distribution is two-fold: (1) the log-normal distribution has a lower bound of zero. For our data we generally consider negative ikis as mistakes which occasionally occur when the next key was pressed before the current key. Other than that keystroke intervals are constrained by a persons ability to move their fingers and keyboard polling. (2) the log-scale is known to be a better match for data from human behaviour, in particular motor responses. In particular, a normal distribution assumes that units are linearly scaled. For example, a 50 msecs difference is the same between 100 msecs and 150 msecs than it is between 5 secs and 5 secs 50 msecs (i.e. 5,050 msecs). This is not necessarily plausible for keystroke data. We would assume that differences that are due to motor activity (typing a high frequency bigram vs a low frequency bigram) are smaller than difference that are due to high levels of cognitive activity (retrieving a word in your L1 or L2). Log-normal distributions are a natural way of scaling units so that a 50 msecs difference on the lower end of the iki scale (motor activity) is more meaningful than a 50 msecs difference on the upper end of the iki scale (retrieving words, planning sentences).

The model can be described like this:

\begin{equation}
\begin{aligned}
(\#eq:unimodloggaus)
\text{iki}_i & \sim \text{logN}(\mu_i, \sigma_\text{e}^2) \\
\text{where: } &
\mu_i = \beta_\text{location[i]} + \text{participant}_i\\
& \text{participant} \sim \text{N}(0, \sigma_\text{p}^2) \\
\text{constraint: } & \sigma_\text{e}^2, \sigma_\text{p}^2>0
\end{aligned}
\end{equation}

### Unimodal unequal-variance log-Gaussian

\begin{equation}
\begin{aligned}
(\#eq:unimoduv)
\text{iki}_i & \sim \text{logN}(\mu_i, \sigma_{e_\text{location[i]}}^2) \\
\text{where: } & \mu_i = \beta_\text{location[i]} + \text{participant}_i\\
 & \text{participant} \sim \text{N}(0, \sigma_\text{p}^2) \\
 \text{constraint: } & \sigma_\text{e}^2, \sigma_\text{p}^2>0
\end{aligned}
\end{equation}

### Bimodal log-Gaussian (constrained)

This models extends the intuition from the previous model that higher levels of activation lead to longer pauses. Instead of assuming that there is one process that underlies the generation of ikis, we assume there are two. (1) activation can flow into keystrokes without interrupts. These fluent keystroke transitions are merely limited by a person's ability to move their finger and will be captured but the parameter $\beta$. In principle, there are no differences for fluent key-transitions between transition location. The next model with loosen this assumption (hence, "unconstrained model"). (2) difficulty in the activation flow leads to pauses when fingers have to catch-up with cognitive activity, when spelling, words, or contents couldn't be retrieved in time. The size of these pauses will depend on the reason for delays which is typically associated with transition locations (contents are typically planned before sentences, words are retrieved before they are typed and spelling difficulty typically occurs when typing a word). Pauses will be captured by two model parameters: (1) the slowdown for these hesitant transitions will be captured by $\delta$ which is the deviation compared to normal typing intervals (constrained to be positive). (2) the frequency of hesitant transitions will be captured by $\theta$ for each level of a categorical predictor. 

\begin{equation}
\begin{aligned}
(\#eq:bimodcon)
\text{iki}_{i} & \sim \theta_\text{location[i]} \cdot \text{LogN}(\beta + \delta_\text{location[i]} + \text{participant}_i, \sigma_{e'_\text{location[i]}}^2) + \\
  & (1 - \theta_\text{location[i]}) \cdot \text{LogN}(\beta + \text{participant}_i, \sigma_{e_\text{location[i]}}^2)\\
\text{where: } & \text{participant} \sim \text{N}(0, \sigma_\text{p}^2) \\
\text{constraint: } & \delta, \sigma_{e}^2, \sigma_\text{e'}^2, \sigma_\text{p}^2>0\\
		& \sigma_{e'}^2 > \sigma_{e}^2
\end{aligned}
\end{equation}

```{r}
#		<!-- &\delta \sim \text{N}(0,1)\\ -->

```


This models takes into account two source = s of participant-specific error: (1) each participant has an individual fluent typing as in the previous models; (2) each participant has in individual hesitation frequency that differs across levels of the categorical predictor.


### Bimodal log-Gaussian (unconstrained)

This model is identical to the previous model with one exception. The distribution of fluent keystroke transitions captured by $\beta$ was fixed to be the same across transition locations is the previous model. In other words, the mean $\beta$ and it's standard deviation $\sigma_{e}^2$ was the same for before-sentence, before-word, and within-word transitions. This means, because of the naturally larger number of within-word transitions, the posterior is dominated by within-word transitions. 

In this model we will loosen this constraint and allow $\beta$ and $\sigma_{e}^2$ to vary by transition-location.

\begin{equation}
\begin{aligned}
(\#eq:bimoduncon)
\text{iki}_{i} &\sim \theta_\text{location[i]} \cdot \text{LogN}(\beta_\text{location[i]} + \delta_\text{location[i]} + \text{participant}_i, \sigma_{e'_\text{location[i]}}^2) + \\
  & (1 - \theta_\text{location[i]}) \cdot \text{LogN}(\beta_\text{location[i]} + \text{participant}_i, \sigma_{e_\text{location[i]}}^2)\\
	\text{where: }  & \text{participant} \sim \text{N}(0, \sigma_\text{p}^2) \\
\text{constraint: } & \delta, \sigma_{e}^2, \sigma_\text{e'}^2, \sigma_\text{p}^2>0\\
		& \sigma_{e'}^2 > \sigma_{e}^2
\end{aligned}
\end{equation}

```{r}
#<!-- & \delta \sim \text{N}(0,1)\\ -->

```
	

## Data sets

Five datasets with keystroke data from text production were used for analysis. An overview can be found in Table \ref{tab:datasets}.

\blandscape
```{r datasets, results='asis'}
tibble(Dataset = c("C2L1", "CATO", "SPL2", "PLanTra", "LIFT", "GUNNEXP2"),
                Source = c("Rønneberg et al. (2022)",
                           "Torrance et al. (2016)",
                           "Torrance et al. (n.d.)",
                           "Rossetti and Van Waes (2022)",
                           "Vandermeulen et al. (2020)", 
                           "Torrance and Ofstad (n.d)"),
                Keylogger = c("EyeWrite", 
                           "EyeWrite", 
                           "CyWrite", 
                           "InputLog", 
                           "InputLog",
                           "EyeWrite"),
                `Writing task` = c("Argumentative essays", 
                                 "Expository texts",
                                 "Argumentative essays",
                                 "Text simplification",
                                 "Synthesis", 
                                 ""),
                 `N (ppts)` = as.character(c(126, 26*2, 39, 47, 658, 45)),
#                n_texts = c(1, 2, 2, 2, NA),
#                n_sentences = c(),
#                n_words = c(),
                `Mean age` = c(11.8, 16.9, 20.6, 23, 16.95, NA),
                 Language = c( "Norwegian", 
                               "Norwegian", 
                               "English (L1) / Spanish (L2)", 
                               "English (L2)", 
                               "Dutch",
                               "Norwegian"),
                Manipulation = c("--", 
                               "weak decoders / control; masked / unmasked",
                               "write in L1 / L2",
                               "pre / post test trained in plain language principles and control", 
                               "Various topics and genres",
                               "masked / unmasked")) %>% 
  arrange(Dataset) %>% 
  apa_table(align = c(rep("l", 4), rep("r", 2), "p{2cm}", "p{3cm}"), 
            escape = FALSE, 
            font_size = "footnotesize",
            caption = "Datasets in brief.")

```
\elandscape




### GUNNEXP2

TODO: Mark, can you add information here? I've added a provisional bib entry that needs changing or we just say "unpublished"



The GUNNEXP2 dataset published in @torranceb includes keystroke data from a text composition task performed by Norwegian undergraduate students (mean age: XXX). In this dataset participants wrote text either in a masked condition in which the produced text was replaced by 'x's or in an unmasked condition in which the students composed text as normal. Keystroke data were captured using EyeWrite [@sim07; XXXX].



### C2L1

TODO: Mark, can you add information here?

TODO: might need to remove kids that don't speak Norwegian at home (see github issue)?

The C2L1 data set comprises data Norwegian 6th graders -- *N*=126, mean age 11 years 10 months -- published in @ronneberg2022process. The children composed argumentative essays in Norwegian, a language with a relatively shallow orthography. Keystroke data were captured using EyeWrite [@sim07; XXXX].




### CATO

TODO: Mark, can you add information here?

Data are published in @torrance2016adolescent. Norwegian upper secondary students--*N*=26, mean age = 16.9 years--with weak decoding skills and 26 age-matched controls composed expository texts by keyboard under two conditions: normally and with letters masked to prevent them reading what they were writing. Keystroke data were captured using EyeWrite [@sim07; XXXX].


### PLanTra

TODO: Rianne, can you add information here?


The PLanTra (Plain Language for Financial Content: Assessing the Impact of Training on Students' Revisions and Readers' Comprehension) data set [@rossetti2022s] involved the collection of keystroke data from 47 university students, who were randomly divided into an experimental and a control group. In a pre-test session, all students were assigned an extract of a corporate report dealing with sustainability and were instructed to revise it to make it easier to read for a lay audience. Subsequently, the experimental group received training on how to apply plain language principles to sustainability content, while the control group received training exclusively on the topic of sustainability. During a post-test session, both groups were instructed to revise a second extract of a corporate sustainability report with the same goal--i.e. making it easier to read for a lay audience--by applying what they had learned from their respective training. The texts were in English while the participants were native speakers of other languages (mainly Dutch), so writing took place in second language. It should be pointed out that, while some students decided to revise the assigned texts, the majority of them opted for rewriting the texts from scratch. Keystroke data were captured using InputLog [@leijten2013keystroke; @van2019multilingual; @waes2019].




### LIFT

TODO: Rianne, can you add information here?

The LIFT (Improving Pre-university Students' Performance in Academic Synthesis Tasks with Level-up Instructions and Feedback Tool) data are published in @vandermeulen2020. Students produced text for 4 topics in two different writing genres (levels: argumentative text, informative text). Keystroke data were captured using InputLog [@leijten2013keystroke; @van2019multilingual; @waes2019].



### SPL2

TODO: Mark, can you add information here?


The SPL2 dataset is published in @torrancea. The data come from a textcomposition task of undergraduate university students -- *N* = 39, 28 female, mean age = 20.6 years (SD = 1.51) -- who wrote two short argumentative essays, one in English (the student's first language in all cases; L1) and one in Spanish (L2) using CyWrite [@chukharev2019combined]. CyWrite provides a writing environment with basic word processing functionality (e.g., Microsoft WordPad), including text selection by mouse action, and copy-and-paste. We recorded the time of each keystroke and mouse action, and tracked writers' eye movements within their emerging text. Participants were given a 40 minute time limit. They wrote essays in response to each of two prompts, with order and L1 / L2 counterbalanced across subjects.



## Data analysis

### Bayesian modelling

We reanalysed keystroke data from 6 datasets in Bayesian implementations of 5 statistical models. 
Bayesian models, as used in this paper, are ideal for the estimation of parameter values: Bayesian parameter estimates are expresses the uncertainty associated with parameter values as probability distribution [@farrell2018computational; @gelman2014; @lee2014bayesian]. To achieve this, Bayesian models require the explicit inclusion of prior information, i.e. existing knowledge about parameter values, for regulating the parameter space. For small data sets priors influence the inferred parameter estimates (known as posterior); for larger data sets weakly informative and vague priors are quickly overcome by the data [i.e. automatic Ockham's razor, @jefferys1992ockham]. In other words the choice of priors values has less impact on the posterior. In the present paper, we use weakly informative priors to aid model convergence by constraining the parameter space [see e.g. @lambert2018student; @mcelreath2016statistical]. The predictive performance (i.e. fit) of these models is compared in the Results section using leave-one-out cross-validation.

Keystroke data from text composition tasks were modelled in a series of five models. An overview of all models can be found in Table \ref{tab:models}.


```{r models, results = 'asis'}
models <- tibble(Models = paste0("M",1:5),
       Type = c("LMM", "LMM", "LMM", "MoG", "MoG"),
       `Eq.` = str_c("\ \\ref{eq:", c("unimodgaus", "unimodloggaus", "unimoduv", "bimodcon", "bimoduncon"), "} "),
       Description = c("Gaussian distribution",
                       "Log-normal distribution",
                       "Log-normal distribution and unequal variances",
                       "Fluent transition are not allowed to vary by transition location",
                       "Fluent transition are allowed to vary by transition location")) 

apa_table(models, 
          align = c(rep("l", 2), "r", "p{9cm}"), 
          escape = FALSE, 
          digits = 0,
          caption = "Overview of typing-process models. All models were fitted with random intercepts for participants.",
          note = "LMM = Unimodal mixed-effects models; MoG = bimodal mixture of log-Gaussians") 
```


For all models we modelled transition locations (levels: before sentence, before word, within word) was included as predictor in all models. Also, we included the dataset specific experimental conditions as fixed effects and included random intercepts for participants as described in the equations above. We used normal and log-normal probability function in line with typically treatments fouund in the literature. Stan code for mixture models was based on @roeser2021modelling  [see also @vasishth2017; @vasishth2017feature]. 

Data were analysed in Bayesian mixed effects models [@gelman2014;@mcelreath2016statistical]. The R [@R-base] package rstan [@rstan] was used to interface with the probabilistic programming language Stan [@carpenter2016stan] which was used to implement all models. Models were fitted with weakly informative priors [see @mcelreath2016statistical], and run with 20,000 iterations on 3 chains with a warm-up of 10,000 iterations and no thinning. Model convergence was confirmed by the Rubin-Gelman statistic ($\hat{R}$ = 1) [@gelman1992] and inspection of the Markov chain Monte Carlo chains.


### Transition types

The transition types that were analysed in this study focuses on those locations that were found, by previous research, to be psycholinguistically meaningful [e.g. @torrancea; @chukharev2019combined; @torrance2016adolescent; @de2018exploring] and are detailed in Table \ref{tab:keyloc}. Keytransitions that terminated in an editing operation were excluded from the analysis. Transitions that occurred at the beginning of the text or the beginning of a paragraph were not treated as before-sentence transitions.

```{r keyloc, results='asis'}

table <- tibble(`Transition type` = c("Within word", "Below word", "Before sentence"),
       Description = c("Transitions between any letter",
                       "Keypress after space followed by any letter",
                       "Keypress following a space preceding any letter"),
       Example = c("T$^{\\wedge}$h$^{\\wedge}$e c$^{\\wedge}$a$^{\\wedge}$t m$^{\\wedge}$e$^{\\wedge}$o$^{\\wedge}$w$^{\\wedge}$e$^{\\wedge}$d. T$^{\\wedge}$h$^{\\wedge}$a$^{\\wedge}$t[bsp][bsp]e$^{\\wedge}$n i$^{\\wedge}$t s$^{\\wedge}$l$^{\\wedge}$e$^{\\wedge}$p$^{\\wedge}$t.", 
                   "The $^{\\wedge}$cat $^{\\wedge}$meowed. That[bsp][bsp]en $^{\\wedge}$it $^{\\wedge}$slept.", 
                   "The cat meowed. $^{\\wedge}$That[bsp][bsp]en it slept."))

apa_table(table, caption = "Transition location classification.",
            align = c("p{3cm}", "p{3cm}", "p{8cm}"), 
            escape = FALSE, 
            font_size = "footnotesize",
            note = "$'^{\\wedge}$' marks transition location; [bsp] represents backspace. At before-sentence locations, IKIs were timed to the shift keypress.")

```





### Data reduction

```{r reductionfunctions}
source("scripts/get_data_summary.R")

# Get info about data reduction
n_samples <- 100
c2l1 <- get_c2l1("../data/c2l1.csv", n_samples = n_samples)
cato <- get_cato("../data/cato.csv", n_samples = n_samples)
lift <- get_lift("../data/lift.csv", n_samples = 50, n_ppts = 100)
plantra <- get_plantra("../data/plantra.csv", n_samples = n_samples)
spl2 <- get_spl2("../data/spl2.csv", n_samples = n_samples) 
gunnexp2 <- get_gunnexp2("../data/gunnexp2.csv", n_samples = n_samples)
```


For all datasets we only used transitions that were not followed by an editing operation.

We removed participants that did not complete all conditions in studies with within-participant factors (reducing the number of participants to 343 in the LIFT data set, and 41 participants in the PLanTra data set). We removed participants that produced less than 10 sentences (LIFT: 109 participants; PLanTra: 3 participants; SPL2: 1 participant)

We removed keystroke intervals that are extremely short ($\le$ 50 msecs) or extremely long ($\ge$ 30 secs). The percentage of remove keystroke data can be found in Table \ref{tab:datareduction}.

From the remaining data we randomly sampled `r n_samples` observations per participant, per condition, and per transition location, with the exception of the LIFT data set. This was done for computational reasons to reduce the time the Bayesian models need to complete. For the LIFT data set we reduced the number of participants to 100 which is substantially more than most of the other data sets in our analysis. Because we included the large number of writing tasks in the LIFT data set as fixed effect, we sampled 50 observations per condition, location and participant. The percentage of keystroke data that went into the final analysis can be found, by transition location, in Table \ref{tab:datareduction}.


```{r datareduction, results='asis'}
c2l1$ds <- "c2l1"
cato$ds <- "cato"
lift$ds <- "lift"
plantra$ds <- "plantra"
spl2$ds <- "spl2"
gunnexp2$ds <- "gunnexp2"

extrem_values <- map_dfr(list(c2l1, cato, lift, plantra, spl2, gunnexp2), ~.x[[1]] %>% 
          mutate(ds = .x$ds)) %>% 
  mutate(across(where(is.numeric), ~round(.*100, 2))) %>% 
  unite("<50ms", starts_with("too_fast"), sep = " (") %>% 
  unite(">30,000ms", starts_with("too_slow"), sep = " (") %>% 
  mutate(across(c(`<50ms`, `>30,000ms`), ~str_c(., ")"))) %>% 
  rename(`$\\le$ 50 msecs` = `<50ms`,
         `$\\ge$ 30 secs` = `>30,000ms`)
  
random_sample <- 
  map_dfr(list(c2l1, cato, lift, plantra, spl2, gunnexp2), ~.x[[2]] %>% 
          mutate(ds = .x$ds)) %>% 
    mutate(across(where(is.numeric), ~round(.*100, 1))) %>%
    unite("keep", starts_with("keep"), sep = " (") %>% 
    mutate(across(c(keep), ~str_c(., ")"))) %>%
  pivot_wider(names_from = location, values_from = keep)

datareduction <- left_join(extrem_values, random_sample, by = "ds") %>% 
  relocate(ds) %>% 
  mutate(across(ds, ~recode(., 
                "cato" = "CATO",
                "spl2" = "SPL2", 
                "spl2_shift" = "SPL2 (shift + C)", 
                "plantra" = "PLanTra",
                "lift" = "LIFT",
                "c2l1" = "C2L1",
                "gunnexp2" = "GUNNEXP2"))) %>% 
  rename(`Dataset` = ds)

apa_table(datareduction, 
          escape = FALSE,  
          placement = "bp!",
          caption = "Data reduction. Mean percentage of extreme data removed and the mean percentage of randomly sampled data by transition location. Standard error is shown in parentheses.",
          align =c("l", rep("r", 5)),
          col_spanners = list(" " = 1,
                              "Extreme values in \\%" = c(2, 3),
                              "Randomly sampled data in \\%" = c(4, 6))) 

```





# Results

## Out-of-samples cross-validation

To compare the out-of-sample predictive performance of the models we used Pareto smoothed importance-sampling leave-one-out cross-validation [@vehtari2015pareto; @vehtari2017practical]. Predictive performance was estimated as the sum of the expected log predictive density ($\widehat{elpd}$) and its  difference $\Delta\widehat{elpd}$ between models. The advantage of using leave-one-out cross-validation is that models with more parameters are penalised to prevent overfit.

Results for all data sets are shown in Table \ref{tab:loos}. For all data sets we found the same pattern. The mixture of log-normal distribution models provided a substantially better fit than any of the uni-modal distribution models. The unconstrained version of the mixture of log-normal distributions rendered a higher predictive performance than the constrained version that does not allow the distribution of short keystroke-intervals to vary across transition locations. 

We also evaluated to what extent model predictions fit observed data. These comparisons can be found in Appendix \ref{fit-to-data} and echo the findings reported in the model comparisons in Table \ref{tab:loos}.


```{r}
files <- list.files(
  str_c("../stanout/", 
  c("lift", "spl2", "spl2_shift", "plantra", "cato", "c2l1", "gunnexp2")), 
  pattern = "model.+.csv", 
  full.names = T)

table <- purrr::map_dfr(files, ~read_csv(.) %>% 
                          mutate(dataset = .x)) %>% 
  select(dataset, model, elpd_diff, se_diff, elpd_loo, se_elpd_loo) %>%
  mutate(across(dataset, ~sub(".*/([^/]+)/[^/]+\\..*", "\\1", .)),
         across(where(is.numeric), ~round(., 0)),
         across(where(is.numeric), ~format(., big.mark = ",")),
         across(everything(), ~str_trim(.))) %>%
  filter(dataset != "spl2_shift") %>% 
  transmute(
     across(dataset, ~recode(., 
                "cato" = "CATO",
                "spl2" = "SPL2", 
#                "spl2_shift" = "SPL2 (shift + C)", 
                "plantra" = "PLanTra",
                "lift" = "LIFT",
                "c2l1" = "C2L1",
                "gunnexp2" = "GUNNEXP2")),
    m = recode(model, 
               lmmgaus = "M1",
               lmm = "M2",
               lmmuneqvar = "M3",
               mogbetaconstr = "M4",
               mogbetacontr = "M4",
               mogbetaunconstr = "M5"),
    across(model, ~recode(., lmm = "Unimodal log-normal",
                          lmmgaus = "Unimodal normal",
                          mogbetaconstr = "Bimodal (constrained)",
                          mogbetacontr = "Bimodal (constrained)",
                          mogbetaunconstr = "Bimodal (unconstrained)",
                          lmmuneqvar = "Unimodal (unequal variance)")),
            across(elpd_diff, ~str_c(., " (", se_diff, ")")),
            across(elpd_loo, ~str_c(., " (", se_elpd_loo, ")"))) %>% 
  mutate(across(elpd_diff, ~str_replace(., "0 \\(0\\)", "--"))) %>% 
  arrange(dataset)
```


```{r loos, results='asis'}
names(table)[-1] <- c("Model", "Description", rep(c("$\\Delta\\widehat{elpd}$", "$\\widehat{elpd}$"), 1))

apa_table(table[,-1], 
      caption = "Model comparisons. The top row shows the models with the highest predictive performance. Standard error is shown in parentheses.",
      align =c("p{3.5cm}", "p{6cm}", rep("r", 2)), 
      escape = FALSE,
      longtable = T,
      font_size = "small",
      note = "$\\widehat{elpd}$ = predictive performance indicated as expected log pointwise predictive density; $\\Delta\\widehat{elpd}$ = difference in predictive performance relative to the model with the highest predictive performance in the top row.",
      stub_indents = list(
                     "\\textbf{CL21}" = 1:5,
                     "\\textbf{CATO}" = 6:10,
                     "\\textbf{GUNNEXP2}" = 11:15, 
                     "\\textbf{LIFT}" = 16:20,
                     "\\textbf{PLanTra}" = 21:25,
                     "\\textbf{SPL2}" = 26:30))
#                     "\\textbf{SPL2 (shift + C)}" = 31:35)) 

```


## Cross-data set comparisons




```{r}
files <- list.files(str_c("../stanout/", 
                          c("lift", "spl2", "plantra", "cato", "c2l1", "gunnexp2")), 
                    pattern = "mogbetaun.+.csv", 
                    full.names = T)

ps <- purrr::map_dfr(files, ~read_csv(.x) %>% 
  mutate(data = .x)) %>% 
  mutate(across(data, ~sub(".*/([^/]+)/[^/]+\\..*", "\\1", .)),
         across(data, ~recode_factor(., 
                "cato" = "CATO (non-dyslexic\nunmasked)",
                "gunnexp2" = "GUNNEXP2 (unmasked)",
                "spl2" = "SPL2 (L1)", 
#                "spl2 (shift + C)" = "SPL2 (L1; shift + C)", 
                "plantra" = "PLanTra",
                "lift" = "LIFT",
                "c2l1" = "C2L1",
                .ordered = TRUE))) %>% 
  filter(!(str_detect(data, "SPL2") & lang == "ES"),
         !(str_detect(data, "CATO") & group == "dyslexic"),
         !(str_detect(data, "CATO") & task == "masked"),
         !(str_detect(data, "GUNNEXP2") & xn == "masked")) %>% 
  pivot_wider(names_from = param, 
              values_from = value) %>% 
  unnest(cols = beta:theta) %>% 
  mutate(across(c(beta, beta2), ~exp(.)),
         delta = beta2 - beta,
         across(location, ~str_replace(., " ", "\n"))) %>% 
  pivot_longer(beta:theta) %>% 
  summarise(across(value, 
                   list(mean = mean, 
                        lower = lower, 
                        upper = upper),
                   .names = "{.fn}"), 
            .by = c(data, location, name)) %>% 
  filter(name %in% c("beta", "delta", "prob"))
```


As detailed above the mixture model captures the writing process in three conceptually important parameter values: (1) the transition duration associated with fluent writing (which we indicated as $\beta$), (2) the size of the slowdown for hesitant transitions (indicated as $\delta$), and (3) the mixing proportion which represents the probability of hesitant transition durations (indicated as $\theta$). 

We present the mixture-model estimates for each of the three parameter values in Figure \ref{fig:crossstudypost}. Although models were fitted with all dataset-specific condition, we aggregated across conditions^[We aggregated across pre-post test for the PLanTra dataset as well as genre and topic of the LIFT data set. We demonstrate in Appendix \ref{pre-post-test-plantra} and \ref{genre-effect-lift} respectively that there is negligible evidence for differences between these conditions], and removed conditions that might conflate comparisons^[We removed masked writing condition in the GUNNEXP2 and CATO, the dyslexic group in the CATO dataset, and L2 writing in the SPL2 data. Appendix \ref{masking-effect-cato-gunnexp2} and \ref{l2-effect-spl2} demonstrate that evidence for differences in parameter values for the involved manipulations.]. For posteriors of all conditions within dataset see Appendix \ref{posterior-parameter-estimates}. The posterior of the remaining conditions allows us to compare differences between transition locations within dataset associated with each of the three mixture-model parameters. 



```{r crossstudypost, fig.cap="Estimates across studies. Posterior parameter distribution represented as estimate and 95\\% probability interval (PI)."}

posd <- position_dodge(.65)
dotsize <- 2.5
grouplabel <- "Data set"
shapes <- c(1, 4, 6, 7, 8, 9, 11)
width <- 0
linewidth <- .75
beta <- filter(ps, name == "beta") %>% 
  mutate(name = beta_label) %>% 
  ggplot(aes(y = mean, 
             ymin = lower, 
             ymax = upper,
             x = location,
             shape = data,
             group = interaction(data))) +
  geom_line(linewidth = linewidth, 
            alpha = .35, 
            position = posd) +
  geom_errorbar(width = width, alpha = .75, position = posd) +
  geom_point(aes(colour = data), 
            size = dotsize, 
            position = posd) +
  facet_grid(~name) +
  scale_shape_manual(values = shapes) +
  scale_colour_colorblind() +
  scale_y_log10(labels = scales::comma) +
  theme(axis.title = element_blank()) +
  labs(colour = grouplabel,
       shape = grouplabel) +
  guides(colour=guide_legend(nrow=2,byrow=TRUE),
         shape = guide_legend(nrow=2,byrow=TRUE))

delta <- filter(ps, name == "delta") %>% 
  mutate(name = delta_label,
         across(c(mean, lower, upper), ~./1000)) %>% 
  ggplot(aes(y = mean, 
             ymin = lower, 
             ymax = upper,
             x = location,
             shape = data,
             group = interaction(data))) +
  geom_line(linewidth = linewidth, alpha = .35, position = posd) +
  geom_errorbar(width = width, alpha = .75, position = posd) +
  geom_point(aes(colour = data), 
            size = dotsize, 
            position = posd) +
  facet_grid(~name) +
  scale_shape_manual(values = shapes) +
  scale_colour_colorblind() +
  scale_y_log10(labels = scales::comma) +
  labs(colour = grouplabel,
       shape = grouplabel) +
  theme(axis.title = element_blank()) +
  guides(colour=guide_legend(nrow=2,byrow=TRUE),
         shape = guide_legend(nrow=2,byrow=TRUE))


theta <- filter(ps, name == "prob") %>% 
  mutate(name = theta_label) %>% 
  ggplot(aes(y = mean, 
             ymin = lower, 
             ymax = upper,
             x = location,
             shape = data,
             group = interaction(data))) +
  geom_line(linewidth = linewidth, alpha = .35, position = posd) +
  geom_errorbar(width = width, alpha = .75, position = posd) +
  geom_point(aes(colour = data), 
            size = dotsize, 
            position = posd) +
  facet_grid(~name) +
  scale_shape_manual(values = shapes) +
  scale_colour_colorblind() +
  scale_y_continuous(labels = dezero_plot, limits = c(0, 1)) +
  labs(colour = grouplabel,
       shape = grouplabel) +
  theme(axis.title = element_blank()) +
  guides(colour=guide_legend(nrow=2,byrow=TRUE),
         shape = guide_legend(nrow=2,byrow=TRUE))

plot <- beta + delta + theta +
  plot_layout(guides = "collect")

grid.arrange(patchworkGrob(plot), 
             left = "Posterior estimate with 95% PIs",
             bottom = "Transition location")

```

Figure \ref{fig:crossstudypost} shows largely the same patterns for keystroke interval estimates by transition location across datasets for all three mixture model parameters. keystroke transitions were substantially longer for the C2L1 data presumably reflecting that the sample of in this dataset was the youngest. Pause durations and frequencies were relatively similar across datasets.

In the following we will evaluate differences between transition locations for all three mixture model parameters. This is interesting because it is generally believed that pausing behaviour is associated with syntactic edges such that more and longer pauses are predicted for key transitions at larger syntactic edges following the pattern before-sentence $>$ before-word $>$ within-word. We evaluated the differences between transition locations for all data sets. The results are shown in Table \ref{tab:loceffect}. 

Comparing transition locations rendered patterns that are largely consistent across data sets (with caveats). We found that hesitations appear more frequently at before-word transitions than within words across datasets. Also hesitations are longer at before-sentence transitions compared to before-word transitions (except dataset C2L1) compared to within-word transitions (except dataset LIFT). However, for most dataset there is negligble evidence for the idea that writers pause more frequently at before-sentence locations compared to before-word locations (except for datasets SPL2 and GUNNEXP2). In fact, the dataset LIFT showed less pausing before sentences compared to before words. Also, we observe that even fluent key-transitions are slower at before-word locations compared to within-word locations but there is generally not difference for fluent transitions for before-sentence transitions compared to before-word transitions (except for datasets SPL2 and GUNNEXP2). Hesitation durations tend to be longer at before-sentence locations compared to before-word locations (except for datasets C2L1 and LIFT) and longer for before-word locations compared to within-word locations (except for the LIFT dataset).

In brief, while keystroke transitions and pauses tend to be longer and more frequent at before-word locations compared to within-word transitions, it is not clear in which contexts keystroke transitions are before-sentence locations are slower, and their hesitations are longer and more frequent. 

The inconsistencies for before-sentence transitions could, to some extent, be explained on the basis that datasets differ as to whether before-sentence transitions should be analysed as complex key combination. In particular, some data include the character key following the shift key at before sentence location (PLanTra, LIFT) but others did not (CATO, C2L1, SPL2, GUNNEXP2) scope over the character following the shift key. Notice though that for the datasets PLanTra and LIFT, there were no consistent differences between before-sentence and before-word transitions (except for longer hesitations in the PLanTra dataset). 

We test to what extent this difference may affect the modelling results for the SPL2 dataset. The results are shown in Appendix \ref{key-combination-effect-spl2}. We found that including the character following the shift key substantially extends both the transition duration and the hesitation duration but not the hesitation frequency. However, this is in conflict with the absence of differences in datasets that included the character following shift at before-sentence transitions. In other words, it is unlikely that patterns in our results can be explained on the basis of complex key combinations at before-sentence locations.

Further comparisons can be found in the Appendix: L2 effect (SPL2) in Appendix \ref{l2-effect-spl2}; masking effect (CATO, GUNNEXP2) in Appendix \ref{masking-effect-cato-gunnexp2}; pre-post test effect (PLanTra) in Appendix \ref{pre-post-test-plantra}; genre effect (LIFT) in Appendix \ref{genre-effect-lift}. 

\blandscape
```{r loceffect, results='asis'}
files <- list.files(str_c("../stanout/", 
c("lift", "spl2", "gunnexp2", "plantra", "cato", "c2l1")), pattern = "mogbetaun.+.csv", full.names = T) # "spl2_shift",

ps_loc_diffs <- purrr::map_dfr(files, ~read_csv(.x) %>% 
  mutate(data = .x)) %>% 
  mutate(across(data, ~sub(".*/([^/]+)/[^/]+\\..*", "\\1", .)),
         across(data, ~recode(., 
                "cato" = "*CATO* (non-dyslexic\nunmasked)",
                "spl2" = "*SPL2* (L1)", 
                "gunnexp2" = "*GUNNEXP2* (unmasked)",
#                "spl2_shift" = "*SPL2* (L1; shift + C)", 
                "plantra" = "*PLanTra*",
                "lift" = "*LIFT*",
                "c2l1" = "*C2L1*"))) %>% 
  filter(!(str_detect(data, "SPL2") & lang == "ES"),
         !(str_detect(data, "CATO") & group == "dyslexic"),
         !(str_detect(data, "CATO") & task == "masked"),
         !(str_detect(data, "GUNNEXP2") & xn == "masked"),
         param %in% c("beta", "delta", "theta")) %>%
  select(param, location, data, value) %>% 
  mutate(across(value, ~ifelse(param == "theta", .*-1, .))) %>% 
  pivot_wider(names_from = location, values_from = value) %>%
  unnest(-c(data, param)) %>% 
  mutate(diff.1 = `before sentence` - `before word`,
         diff.2 = `before word` - `within word`) %>% 
  summarise(across(starts_with("diff"), 
                   list(mean = mean, 
                        lower = lower, 
                        upper = upper, 
                        BF = BF)),
            .by = c(data, param)) 

tmp <- ps_loc_diffs %>% 
  pivot_longer(starts_with("diff"), names_to = c("diffid", ".value"), names_sep = "_") %>% 
  mutate(across(mean, ~pmap_chr(list(., lower, upper, 2), PI)),
         across(BF, ~ifelse(.>100, "> 100", as.character(round(.,2))))) %>% 
  select(-lower, -upper) %>% 
  pivot_wider(names_from = param, values_from = c(mean, BF)) %>% 
  mutate(across(diffid, ~recode(., diff.1 = "before sentence vs word",
                                   diff.2 = "before vs within word"))) %>% 
  select(data, diffid, ends_with("beta"), ends_with("delta"), ends_with("theta")) %>% 
  arrange(data)
  
write_csv(tmp, "tables/location_effect_alldata.csv")

apa_table(tmp[,-1],
          align =c("l", rep("r", 6)), 
          longtable = T,
          escape = FALSE,
          row.names = T,
          font_size = "footnotesize",
          col.names = c("Comparison", rep(c("Est. [95\\% PIs]", "BF"), 3)),
          stub_indents = list(`\\textbf{C2L1}` = 1:2, 
                              `\\textbf{CATO (non-dyslexic, unmasked)}`= 3:4,
                              `\\textbf{GUNNEXP2 (unmasked)}` = 5:6,
                              `\\textbf{LIFT}` = 7:8,
                              `\\textbf{PLanTra}` = 9:10,
                              `\\textbf{SPL2 (L1)}` = 11:12),
#                              `\\textbf{SPL2 (L1; shift + C)}` = 13:14),
          col_spanners = list(" " = c(1),
                     "Fluent transitions" = c(2, 3), 
                     "Hesitation slowdown" = c(4, 5), 
                     "Hesitation probability" = c(6, 7)),
          note = "PI = probability intervals. BF = evidence in favour of the alternative hypothesis over the null hypothesis.",
         caption = "Effect of transition location on keystroke intervals. Differences are shown on log scale (for transition durations) and logit scale for probability of hesitant transitions. 95\\% PIs in brackets.") 


```
\elandscape

## Simulation

A possible concern with the results -- substantially better predictive performance for mixture models -- is that, in principle, as the mixture model has more parameters it might always lead to a better fit. We addressed this concern before by using cross-validation techniques for model comparison which is preventing overfitting models.

To address this concern we repeated a comparison for an unimodal model and a mixture model for two sets of simulated data. For each dataset we simulated 1,000 observations.

These two datasets differ with regards to their underlying data generating process. The first set of data has as underlying data generating process a mixture model with two mixture components similar to the process described above. This process and the corresponding Bayesian model is summarised in equation \ref{eq:simmog}.

\begin{equation}
\begin{aligned}
(\#eq:simmog)
\text{y}_i \sim\text{ } & \theta \cdot \text{logN}(\beta + \delta, \sigma^2_1) +\\
& (1 - \theta) \cdot \text{logN}(\beta, \sigma^2_2)\\
\text{constraint: } & \delta, \sigma_\text{2}^2, \sigma_\text{1}^2>0\\
		& \sigma_{1}^2 > \sigma_{2}^2
\end{aligned}
\end{equation}

This model is largely identical with the models before but reduced to its main parameters. There are two log-normal distributions with a mixing proportion $\theta$ of which the distribution of shorter values has a mean of $\beta$ and a standard deviation $\sigma^2_2$; the second distribution of longer values is constrained to have a mean that is larger by a factor of $\delta$ and has a larger standard deviation $\sigma^2_1$.

The second dataset was generated with an unimodal model as data generating process. The model and its corresponding Bayesian model is summarised in equation \ref{eq:simuv}.

\begin{equation}
\begin{aligned}
(\#eq:simuv)
\text{y}_i \sim\text{ }& \text{logN}(\beta, \sigma^2)
\end{aligned}
\end{equation}

Again, this model is a simplified version of the unimodal models used in the main analysis. The model assumes a log-normal distribution with a mean parameter $\beta$ and a standard deviation $\sigma^2$.

The parameter values used for each of the two data simulations can be found in Table \ref{tab:simparam}. The simulated data are visualised in Figure \ref{fig:simdata}. The data are simulated to be similarly distributed to keystroke transitions.

```{r simdata, fig.cap= "Data simulated with a bimodal process (left) and a unimodal process (right).", fig.height=3.5, fig.width=5}
files <- list.files("../mixture-model-sim/data", full.names = T)

map_dfr(files, ~read_csv(.) %>% 
        mutate(Dataset = str_remove_all(.x, "../mixture-model-sim/data|/|.csv" ))) %>%
  mutate(across(Dataset, ~recode(., mogdata = "bimodal", lmdata = "unimodal"))) %>% 
  ggplot(aes(x = value, colour = Dataset, fill = Dataset)) +
  geom_density(alpha = .25) +
  scale_colour_colorblind() + 
  scale_fill_colorblind() +
  scale_x_continuous(labels = ~format(., big.mark = ",")) +
  labs(colour = "Data process", 
       fill = "Data process", 
       x = "Simulated data", 
       y = "Density")
```

We run 4 models, 2 on each of the two datasets: 2 mixture models, one for the data generated with a bimodal mixture process and one for the data generated with the unimodal process. We repeated the same using an unimodal model. Models were run with 3 chains, with each 6,000 iterations of which 3,000 were warmup. Estimates with 95% probability intervals are shown in Table \ref{tab:simparam}. The parameters are shown by data generating process along with with true parameter values. Parameter estimates are shown for the dataset generated with a unimodal process and the dataest generated with a bimodal process. The Bayesian models uncovered the model parameters of the dataset with the matching data generating process successfully, as shown in Table \ref{tab:simparam}, but less so when the model was applied to data generated with the incorrect underlying process.

```{r}
mog1 <- read_csv("../mixture-model-sim/stanout/mog_mogdata.csv") %>% 
  mutate(data = "mog")
mog2 <- read_csv("../mixture-model-sim/stanout/mog_lmdata.csv") %>% 
  mutate(data = "lm")
lm1 <- read_csv("../mixture-model-sim/stanout/lm_lmdata.csv") %>% 
  mutate(data = "lm")
lm2 <- read_csv("../mixture-model-sim/stanout/lm_mogdata.csv") %>% 
  mutate(data = "mog")

mog_sim <- bind_rows(mog1, mog2) %>% 
  summarise(across(value, list(est = mean,
                               lo = lower,
                               up = upper),
                   .names = "{.fn}"),
            .by = c(name, data)) %>% 
  mutate(across(where(is.numeric), ~round(., 2)),
         across(where(is.numeric), ~ifelse(str_detect(name, "prob"), dezero(., 2), .)),
         across(est, ~str_c(., " [", lo, ", ", up, "]")),
         across(name, ~str_c("\\", .)),
         across(name, ~str_replace(., "a_e", "a^2_1")),
         across(name, ~str_replace(., "ap_e", "a^2_2"))) %>%
  select(-lo, -up) %>% 
  pivot_wider(names_from = data, values_from = est) %>% 
  mutate(true = c(5, 1, .35, .25, .5),
         across(true, ~ifelse(str_detect(name, "prob"), dezero(., 2), .)),
         across(name, ~str_replace(., "prob", "theta"))) %>% 
  relocate(name, true) %>% 
  unite("name", name:true, sep = " = ")

lm_sim <- bind_rows(lm1, lm2) %>% 
  summarise(across(value, list(est = mean,
                               lo = lower,
                               up = upper),
                   .names = "{.fn}"),
            .by = c(name, data)) %>% 
  mutate(across(where(is.numeric), ~round(., 2)),
         across(est, ~str_c(., " [", lo, ", ", up, "]")),
         across(name, ~str_c("\\", .)),
         across(name, ~str_replace(., "a_e", "a^2_1")),
         across(name, ~str_replace(., "ap_e", "a^2_2"))) %>% 
  select(-lo, -up) %>%
  pivot_wider(names_from = data, values_from = est) %>% 
  mutate(true = as.character(c(5, .25))) %>% 
  relocate(name, true) %>% 
  unite("name", name:true, sep = " = ")

```




```{r simparam, results='asis'}
table <- bind_rows(mog_sim %>% mutate(model = "mog"),
                   lm_sim %>% mutate(model = "lm")) %>% 
  relocate(model) %>% 
  mutate(across(name, ~str_c("$", ., "$")))

names(table) <- c("Model", "Parameter with true value", "Bimodal data", "Unimodal data")

apa_table(table[,-1], 
          escape = FALSE,
      col_spanners = list("Estimate with 95\\% PI" = 2:3),
      caption = "Uncovered parameter estimates with 95\\% probability interval (PI) and true parameter values for each simulated data set and by model and their respective parameters.",
      align = c("l", rep("r", 2)),
      stub_indents = list(`Bimodal mixture process` = 1:5, 
                          `Unimodal process` = 6:7))


```

We used LOO-CV to compare the fit of the two models for each data set. The model comparisons can be found for each data generating process in Table \ref{tab:loossim}. The results rules out the possibility that the mixture model does always lead to higher predictive performance. Indeed, the mixture model showed a slightly lower predictive performance for the data that were generated with a unimodal process. However, for the data generated with a bimodal process, the mixture model shows a substantially higher predictive performance. 

In fact, the ratio of $\Delta\widehat{elpd}$ and its standard error, as metric for the strength of evidence [@sivula2020uncertainty], shows that the mixture model performs 11.6 times better than the unimodal model for the data generated with a bimodal process. In comparison, for the unimodal data, the unimodal model performs only 0.77 times better than the bimodal mixture model. Thus, even though the mixture model does not necessarily perform better for non-bimodal data, it also does not necessarily perform worse. 


```{r loossim, results='asis'}
table <- read_csv("../mixture-model-sim/stanout/modelcomparison.csv") %>% 
  select(1:6) %>% 
  mutate(
#    elpd_se_ratio = abs(elpd_diff / se_diff),
    across(ends_with("diff"), ~round(., 1)),
    across(ends_with("loo"), ~round(., 0)),
    across(where(is.numeric), ~format(., big.mark = ",")),
    across(everything(), ~as.character(.)),
    across(everything(), ~str_trim(.)),
    across(everything(), ~str_replace_all(., "NaN", "--")),
    across(elpd_diff, ~str_c(., " (", se_diff, ")")),
    across(elpd_loo, ~str_c(., " (", se_elpd_loo, ")")),
    across(elpd_diff, ~str_replace_all(., "0.0 \\(0.0\\)", "--")),
    across(c(data, model), ~recode(., mog = "Bimodal mixture model",
                                      lm = "Unimodal model"))) %>% 
  select(data, model, starts_with("elpd")) 

names(table) <- c("Data", "Model", "$\\Delta\\widehat{elpd}$", "$\\widehat{elpd}$")

apa_table(table[,-1], 
          escape = FALSE,
      caption ="Model comparisons by data set. The top row shows the models with the highest predictive performance. Standard error is shown in parentheses.",
     note = "$\\widehat{elpd}$ = predictive performance indicated as expected log pointwise predictive density; $\\Delta\\widehat{elpd}$ = difference in predictive performance relative to the model with the highest predictive performance in the top row.",
      align =c("l", rep("r", 2)),
      stub_indents = list(`Data: Bimodal mixture process` = 1:2, 
                          `Data: Unimodal process` = 3:4))



```


# Discussion




# References
```{r create_r-references, echo=FALSE, include=FALSE}
r_refs(file = "references.bib")
```

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}
  
<div id = "references"></div>
\endgroup
  



```{r render_appendix, include=FALSE}
render_appendix("appendix_a.Rmd")
render_appendix("appendix_b.Rmd")
render_appendix("appendix_c.Rmd")
render_appendix("appendix_d.Rmd")
render_appendix("appendix_e.Rmd")
render_appendix("appendix_g.Rmd")
render_appendix("appendix_f.Rmd")
```



