We analysed interkey intervals from six existing studies in which participants composed spontaneous, multi-sentence texts in response to writing prompts. The datasets include samples from populations with various writing experience and languages (e.g. young / L2 writers, students) performing different writing tasks (e.g. essays, syntheses). Datasets from a variety of different populations of writers and writing tasks were deliberately chosen to challenge our modelling approach and to test to what extent pausing patterns generalise across writing contexts. 

This study was not preregistered.

## Data sets

Six datasets with keystroke data from free text production were used for analysis. An overview can be found in Table \ref{tab:datasets}; descriptions below. Datasets used are C2l1 [@ronneberg2022process], CATO [@torrance2016adolescent], GE2 [@torranceb], SPL2 [@torrancea], LIFT published in @vandermeulen2020 and described in @vandermeulen2020mapping, and PLanTra published in @rossetti2022text and described in @rossetti2022s. 



\blandscape

```{r datasets, results='asis'}
tibble(Dataset = c("C2L1", "CATO", "SPL2", "PLanTra", "LIFT", "GE2"),
                Source = c("RÃ¸nneberg et al. (2022)",
                           "Torrance et al. (2016)",
                           "Torrance et al. (n.d.)",
                           "Rossetti and Van Waes (2022b)",
                           "Vandermeulen, Steendam, et al. (2020)", 
                           "Torrance and Ofstad (n.d)"),
                Keylogger = c("EyeWrite", 
                           "EyeWrite", 
                           "CyWrite", 
                           "InputLog", 
                           "InputLog",
                           "EyeWrite"),
                `Writing task` = c("Argumentative essay", 
                                 "Expository essay",
                                 "Argumentative essay",
                                 "Paraphrase technical text$^b$",
                                 "Synthesis of several printed sources$^b$", 
                                 "Argumentative essay"),
                 `Words in text$^a$` = c("128.5 (52.9)", "288 (119)", "668 (301)", "295 (79)", "374 (56)$^d$", "540 (141)"),
#                n_texts = c(1, 2, 2, 2, NA),
#                n_sentences = c(),
#                n_words = c(),
                `Age` = c("11.8 (0.47)", "16.9 (0.88)", "20.6 (1.62)", "23 (2.7)", "16.7 (1.5)", "19.1 (1.4)$^c$"),
                 N = as.character(c(126, 26*2, 39, 47, 658, 45)),
                 Sample = c("6th graders", "Secondary school students (dyslexic, non dyslexic)", "Undergraduate students", "Master students", "Secondary school students", "Undergraduate students"),
                 Country = c("Norway", "Norway", "USA", "Belgium", "The Netherlands", "UK"),
                 Language = c( "Norwegian", 
                               "Norwegian", 
                               "English", 
                               "English (L2)", 
                               "Dutch",
                               "English")) %>% 
  arrange(Dataset) %>% 
  apa_table(align = c("p{1.5cm}", "p{2.75cm}", "p{1.75cm}", "p{2.25cm}", "p{1.75cm}", "p{1.75cm}", "p{.5cm}", "p{2.5cm}", "p{1.75cm}", "p{2cm}"), 
            escape = FALSE, 
            longtable = FALSE,
            row.names = T,
            font_size = "footnotesize",
            caption = 'Datasets in brief.', 
            note = "$^a$Mean number of words in the final text; standard deviations in parentheses. $^b$Reading activity was marked in the dataset and removed before analysis. $^c$Estimated from a similar sample from the same population. $^d$Estimated based on the number of characters in the final product following Brysbaert et al. (2021).")




```

\elandscape


In C2L1 Norwegian 6th graders composed argumentative essays. In CATO upper Norwegian secondary students with and without dyslexia composed expository texts either normally or with masked letters to prevent writers reading their unfolding text. In SPL2 undergraduate students produced argumentative essays in their first language (L1; English) and in a second language L2 (Spanish) in which they were able to compose text but in which their mastery fell well behind their first language. Order of language (L1 / L2) and two writing prompts were counterbalanced. The LIFT data are from pre-university students producing argumentative and informative text syntheses on four topics each. The PLanTra data contains data from Master students in Business and Economics simplifying texts on sustainability, before and after receiving either online instruction on how to apply plain language principles to sustainability content or an online instruction exclusively on the topic of sustainability. The GE2 data are from Undergraduate students producing two argumentative essays on general-knowledge topics in either masked text or normal writing conditions, with masking, topic and order counterbalanced.

For C2L1, CATO, and GE2, keystroke data were captured using EyeWrite [@sim07; @torrance201203]. LIFT and PLanTra data were captured using InputLog [@leijten2013keystroke; @van2019multilingual; @waes2019] and SPL2 data were collected using CyWrite [@chukharev2019combined].



## Data extraction

From the keystroke data we extracted interkey intervals between adjacent keys at locations that have been identified repeatedly in previous research as locations where observed mean interkey intervals (or counts of interkey intervals over a predetermined threshold) have tended to vary substantially [e.g. @chukharev2019combined; @torrance2016adolescent; @de2018exploring] and are detailed in Table \ref{tab:keyloc}. In particular we analysed the interkey intervals that resulted in the insertion of a character that started a new sentence (before-sentence transition); interkey intervals that started a new word (other than those at the beginning of a sentence;  before-word transitions); and transitions between characters within words all transitions. At before-sentence locations, interkey intervals were timed to the shift keypress that resulted in the capitalization of the first key for most data sets (CATO, C2L1, SPL2, GE2) but were timed to the character key press in the  PLanTra and LIFT datasets (i.e. the duration included the time to perform the capitalising shift keypress); we return to this difference in the Results section. Transitions that occurred at the very start of the text or at the beginning of a paragraph were not treated as before-sentence transitions and were removed from the analysis. Importantly we also removed transitions that were followed by an editing operation. We therefore just modelled the times between keypresses in ongoing production.

```{r keyloc, results='asis'}

table <- tibble(`Transition type` = c("Within word", "Before word", "Before sentence"),
       Description = c("Transitions between any letter",
                       "Keypress after space followed by any letter",
                       "Keypress following a space preceding any letter"),
       Example = c("T$^{\\wedge}$h$^{\\wedge}$e c$^{\\wedge}$a$^{\\wedge}$t m$^{\\wedge}$e$^{\\wedge}$o$^{\\wedge}$w$^{\\wedge}$e$^{\\wedge}$d. T$^{\\wedge}$h$^{\\wedge}$a$^{\\wedge}$t[bsp][bsp]e$^{\\wedge}$n i$^{\\wedge}$t s$^{\\wedge}$l$^{\\wedge}$e$^{\\wedge}$p$^{\\wedge}$t.", 
                   "The $^{\\wedge}$cat $^{\\wedge}$meowed. That[bsp][bsp]en $^{\\wedge}$it $^{\\wedge}$slept.", 
                   "The cat meowed. $^{\\wedge}$That[bsp][bsp]en it slept."))

apa_table(table, caption = 'Transition location classification. The final text in all cases was "The cat meowed. Then it slept."',
            align = c("p{3cm}", "p{5cm}", "p{6cm}"), 
            escape = FALSE, 
            font_size = "footnotesize",
            note = "$'^{\\wedge}$' marks transition location; [bsp] represents backspace.")

```

```{r reductionfunctions}
source("../scripts/get_data_summary.R")

# Get info about data reduction
n_samples <- 100
c2l1 <- get_c2l1("../../data/c2l1.csv", n_samples = n_samples)
cato <- get_cato("../../data/cato.csv", n_samples = n_samples)
lift <- get_lift("../../data/lift.csv", n_samples = 50, n_ppts = 100)
plantra <- get_plantra("../../data/plantra.csv", n_samples = n_samples)
spl2 <- get_spl2("../../data/spl2.csv", n_samples = n_samples) 
gunnexp2 <- get_gunnexp2("../../data/gunnexp2.csv", n_samples = n_samples)
```

We removed participants that did not complete all conditions in studies with within-participant factors (reducing the number of participants to 343 for LIFT data, and 41 participants for PLanTra data). We removed participants that produced fewer than 10 sentences (LIFT: 109 participants; PLanTra: 3 participants; SPL2: 1 participant). We further removed keystroke intervals that were too short to represent intentional typing [$\le$ 50 msecs, see @gentner1980finger; @rumelhart1982simulating] or were of a length where such that they were unlikely to be associated with ongoing text production ($\ge$ 30 secs); percentages can be found in Table \ref{tab:datareduction}. From the remaining data we randomly sampled a maximum of `r n_samples` observations per participant, condition, and transition location (when more than `r n_samples` were available). This was done to reduce the computation time of the Bayesian models required to complete sampling. For the LIFT data set we reduced the number of participants to 100 because the total sample was substantially larger than for the other datasets. Because the LIFT data set included the largest number of writing tasks, we sampled 50 observations per condition, location and participant which would otherwise exceed the computational resources available to us. The number of keystroke data used in the analysis can be found in Table \ref{tab:datareduction}.


```{r datareduction, results='asis'}
c2l1$ds <- "c2l1"
cato$ds <- "cato"
lift$ds <- "lift"
plantra$ds <- "plantra"
spl2$ds <- "spl2"
gunnexp2$ds <- "gunnexp2"

extrem_values <- map_dfr(list(c2l1, cato, lift, plantra, spl2, gunnexp2), ~.x[[1]] %>% 
          mutate(ds = .x$ds)) %>% 
  mutate(across(where(is.numeric), ~signif(.*100, 2))) %>% 
  unite("<50ms", starts_with("too_fast"), sep = " (") %>% 
  unite(">30,000ms", starts_with("too_slow"), sep = " (") %>% 
  mutate(across(c(`<50ms`, `>30,000ms`), ~str_c(., ")")),
         across(c(`<50ms`, `>30,000ms`), ~str_replace(., "0 \\(0\\)", "--"))) %>% 
  rename(`$\\le$ 50 msecs` = `<50ms`,
         `$\\ge$ 30 secs` = `>30,000ms`)
  
random_sample <- 
  map_dfr(list(c2l1, cato, lift, plantra, spl2, gunnexp2), ~.x[[2]] %>% 
          mutate(ds = .x$ds)) %>% 
    mutate(across(where(is.numeric), ~signif(.*100, 2))) %>%
    unite("keep", starts_with("keep"), sep = " (") %>% 
    mutate(across(keep, ~str_c(., ")")),
          across(keep, ~str_replace(., "100 \\(0\\)", "--"))) %>%
  pivot_wider(names_from = location, values_from = keep) %>% 
  relocate(`within word`)

datareduction <- left_join(extrem_values, random_sample, by = "ds") %>% 
  relocate(ds) %>% 
  mutate(across(ds, ~recode_factor(., 
                "c2l1" = "C2L1",
                "cato" = "CATO",
                "gunnexp2" = "GE2",
                "lift" = "LIFT",
                "plantra" = "PLanTra",
#                "spl2_shift" = "SPL2 (shift + C)", 
                "spl2" = "SPL2",
                .ordered = T
                ))) %>% 
  arrange(ds) %>% 
  rename(`Dataset` = ds)

apa_table(datareduction, 
          escape = FALSE,  
          placement = "bp!",
          caption = "Data reduction. Shown are the percentage of extreme data that were removed and the percentage of randomly sampled data that were analysed by transition location (`--` if all data were included). Standard error in parentheses.",
          align =c("l", rep("r", 5)),
          col_spanners = list(" " = 1,
                              "Extreme values in \\%" = c(2, 3),
                              "Data analysed in \\%" = c(4, 6))) 

```

## Statistical modelling


We analysed keystroke data in a series of four Bayesian mixed-effects models. An overview of all models can be found in Table \ref{tab:models}. Full modelling details can be found in Appendix \ref{statistical-models} but we summarised the most relevant properties in this section.

The first three models -- models M1, M2, and M3 -- were single-distribution models consistent with the serial account. They were single distribution models, with fixed effects for each combination of transition location and dataset-specific manipulations. Models M1 (Gaussian) and M2 (log-Gaussian) are consistent with standard models used in the literature and therefore serve as baseline models. For model M3 we relaxed the equal-variance assumption for transition locations, thus allowing transition locations on larger linguistic boundaries to assume a larger standard deviation; see Appendix \ref{statistical-models} for rationale.



```{r eval=F}
models <- tibble(Models = str_c("M",1:5),
       Type = c("LMM", "LMM", "LMM", "MoG", "MoG"),
       `Eq.` = str_c("\ \\ref{eq:", c("unimodgaus", "unimodloggaus", "unimoduv", "bimodcon", "bimoduncon"), "} "),
#       group = c(rep("Serial", 3), rep("Cascading", 2)),
       Description = c("Single Gaussian model with effects of transition location.",
                       "Single distribution log-Gaussian model equivialent to M1.",
                       "Equivalent to M2 but with different variance components for each transition location (unequal variance).",
                       "Two-distributions mixture of a log-Gaussian for fluent interkey intervals and another wider log-Gaussian for hesitant interkey intervals; the distribution of hesitant interkey intervals assumes -- similar to M3 -- different values for transition locations. The mixing weight (i.e. proportion of observations estimated to be associated with each distribution) captures the relative number of hesitant transitions for each transition location.",
                       "Equivialent to M4 but distribution of fluent transitions is allowed to vary by transition location.")) %>% 
  select(Models, Description)
```


```{r models, results = 'asis'}
models <- tibble(Models = str_c("M",1:4),
       Type = c("LMM", "LMM", "LMM", "MoG"),
       Description = c("Single Gaussian model with effects of transition location.",
                       "Single distribution log-Gaussian model equivialent to M1.",
                       "Equivalent to M2 but with different variance components for each transition location (unequal variance).",
                       "Two-distributions mixture of a log-Gaussian for fluent interkey intervals and another wider log-Gaussian for hesitant / disfluent interkey intervals; the distribution of hesitant interkey intervals assumes -- similar to M3 -- different values for transition locations. The mixing weight of these distributions capture the relative number of disfluent transitions for each transition location.")) %>% 
  select(Models, Description)


apa_table(models, 
          align = c(rep("l", 1), "p{13cm}"), 
          escape = FALSE, 
          digits = 0,
          caption = "Model overview. All models included by-participant random effect and study-specific manipulations.",
          stub_indents = list(
                     "\\textbf{Serial}" = 1:3,
                     "\\textbf{Parallel}" = 4))

```

Model M4 is a two-distribution mixture model consistent with the parallel cascading account. This model assumes that keystroke data result from a combination of two data generating processes; these models are referred to as finite mixture models in the literature [@gelman2014; @peel2000finite]. Both single-distribution models and the two-distribution mixture model capture that processing difficulty at higher levels of activation leads to longer pauses but only the two-distribution model captures that planning-related pauses may occur at any interkey interval, even mid-word, and that planning may not be reflected in sentence or word-initial pauses when planning happens in parallel to output. In other words, instead of assuming that there is one process that shifts the distribution of transition durations for larger linguistic edges, we allow for the possibility that key-transitions at larger linguistic edges are more likely to reflect processing delays but the cognitive system does not obligate planning to occur before sentences or words. This is achieved by modelling interkey intervals as coming from a weighted mixture of two distributions associated with two different states, illustrated in equation \ref{eq:bimodcon2}: 

1. Information from upstream mental processes can flow into keystrokes without interruption at intermediate levels. These fluent keystroke transitions are merely constrained by a person's ability to move their finger. Fluent interkey intervals (i.e. typing speed) are captured by the $\beta$ parameter. $\beta$ is represented in both log-Gaussian distributions in equation \ref{eq:bimodcon2} referring to the same unknown parameter.

2. Any interruption at upstream levels of mental representation delays the information flow reflected in a resulting lag between keystroke intervals, for example when words or their spelling could not be retrieved in time. The slowdown for such hesitations is captured by $\delta$ and its frequency by the mixing proportion $\theta$. The slowdown $\delta$ was allowed to vary by transition locations because hesitations at larger linguistic units are likely to be associated with higher level planning which causes longer delays in the output. The $\delta$ parameter was constrained to be positive, so that it captures how much longer hesitant interkey intervals are in addition to $\beta$.


\begin{equation}
\begin{aligned}
(\#eq:bimodcon2)
\text{iki}_{i} \sim\text{ } & \theta_\text{location[i], participant[i]} \times \text{log}\mathcal{N}(\beta + \delta_\text{location[i]} + u_\text{participant[i]}, \sigma_{e'_\text{location[i]}}^2) + \\
  & (1 - \theta_\text{location[i], participant[i]}) \times \text{log}\mathcal{N}(\beta + u_\text{participant[i]}, \sigma_{e_\text{location[i]}}^2)\\
\text{where: } & u_\text{participant} \sim \mathcal{N}(0, \sigma_\text{p}^2) \\
\text{constraint: } & \delta, \sigma_{e}^2, \sigma_\text{e'}^2, \sigma_\text{p}^2>0\\
		& \sigma_{e'}^2 > \sigma_{e}^2\\
		& 0 < \theta < 1
\end{aligned}
\end{equation}

The first line of equation \ref{eq:bimodcon2} represents the distribution of hesitant interkey intervals that include the $\delta$ parameter presenting the slowdown for hesitant transitions; the second line represents the distribution of fluent -- uninterrupted -- interkey intervals that is characterised by $\beta$ which is also present in the first file. Either of these two distributions is associated with the mixing proportion $\theta$ that ranges between 0 and 1. $\theta$ was parameterised here to represent the probability that an interkey interval is associated with the distribution of hesitant transitions. This probability is inversely related to the mixing weight of the distribution of fluent transitions by $1-\theta$ . In other words, a larger weight for either distribution inevitably means a lower weight for the other. We call this parameter the probability of hesitant interkey intervals. When a parameter is allowed to vary by transition location (levels: before sentence, before word, within word), this was indicated as subscript; similar for participants. For example, $\theta_\text{location[i], participant[i]}$ means that the mixing proportion $\theta$ is allowed to take on a different value for both the transition location and participant associated with the $i^\text{th}$ keystroke interval $i \in 1 \ldots N$ where $N$ is the total number of keystroke intervals. Because the hesitation probability was allowed to vary by participants as well as location type, we included a hyper-parameter for the mixing proportion $\theta$ for each transition location. 

As with model M3, M4 allowed the variance associated with the key-intervals indicated as $\sigma_{e'}^2$ to vary by transition location. Further each of the two distributions in M4 had its own variance constrained such that the variance associated with the distribution of hesitant keystrokes $\sigma_{e'}^2$ was larger than the distribution of fluent keystroke intervals $\sigma_{e}^2$. This is important because slower human behaviour similar to hesitant keystroke transitions is generally known to be associated with a larger variability [@wagenmakers2007linear; @wing1973response; @schoner2002timing]. Model M4 and all other models included a random intercepts term $u_\text{participants}$ for participants which is constrained to be distributed around 0 with an unknown standard deviation, i.e. $\mathcal{N}(0, \sigma_\text{p}^2)$, hence indicating participant specific deviations from the average typing speed $\beta$.

All models were implemented in the Bayesian framework [@gelman2014; @mcelreath2016statistical]. In the present analysis, we used weakly informative priors to aid model convergence by constraining the parameter space to plausible values [see e.g. @lambert2018student; @mcelreath2016statistical]. Also, as the sample size of most of our datasets is large, weakly informative priors have no or a negligible effect on the posterior. Stan code for mixture models was based on @roeser2021modelling [see also @vasishth2017; @vasishth2017feature] and can be found on OSF [@roeser2024osf]; for a tutorial see [https://rpubs.com/jensroes/mixture-models-tutorial](rpubs.com/jensroes/mixture-models-tutorial).^[The R [@R-base] package rstan [@rstan] was used to interface with the probabilistic programming language Stan [@carpenter2016stan] which was used to implement all models. Models were run with 20,000 iterations on 3 chains with a warm-up of 10,000 iterations and no thinning. Model convergence was confirmed by the Rubin-Gelman statistic ($\hat{R}$ = 1) [@gelman1992] and inspection of the Markov chain Monte Carlo chains. The predictive performance of our models was compared using leave-one-out cross-validation [@vehtari2015pareto; @vehtari2017practical; @sivula2020uncertainty].]


To compare the out-of-sample predictive performance of our models we used leave-one-out cross-validation based on Pareto smoothed importance-sampling [@vehtari2015pareto; @vehtari2017practical]. Predictive performance was estimated as the sum of the expected log predictive density ($\widehat{elpd}$) and compared by the difference between models $\Delta\widehat{elpd}$. We also summarised this difference as normalised over its standard error $\mid\frac{\Delta\widehat{elpd}}{\text{SE}}\mid$, the *z*-score of the difference between models [@sivula2020uncertainty]. Similar to other cross-validation techniques, the advantage of leave-one-out cross-validation is that more complex models -- models with more parameters -- are penalised to prevent overfit.


<!-- The Bayesian framework is ideal for the estimation of parameter values. This is because Bayesian parameter estimates are expresses as probability distributions that capture the associated uncertainty [@farrell2018computational; @gelman2014; @lee2014bayesian]. To achieve this, Bayesian models require the inclusion of prior information, i.e. existing knowledge about parameter values. For small datasets priors influence the inferred parameter values; for larger datasets weakly informative and vague priors are quickly overcome by the data [i.e. automatic Ockham's razor, @jefferys1992ockham]. In other words the choice of priors has less impact on the posterior, certainly for weakly informative priors.  -->


