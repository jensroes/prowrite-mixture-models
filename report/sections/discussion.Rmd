The classical serial view [@flower1980ynamics] characterises composing spontaneous multi-sentence text as a sequence of planning and execution cycles. Text is therefore produced as a series of production bursts bounded by pauses. The parallel model of writing, in contrast, sees  planning, at least in competent writers, as occurring to a large extent in parallel with output [@olive2014toward]. The implication of this for observation of writing timecourse -- of inter-key intervals as writers compose text -- is the pause duration doesn’t necessarily correlated with planning necessary for next output. We implemented  these two views in Bayesian statistical models, hierarchical single-distribution models capturing the serial view, and a two-distribution mixture model capturing predictions about patterning of interkey intervals under the assumption of semi-parallel upstream processing. Fitting these models with six sets of keystroke data from free text production tasks -- with a total of 953 participants producing 5,223,280 interkey intervals -- we have found compelling and consistent statistical evidence in favour of the parallel view. In all cases, the predictive performance of the two-distribution mixture-models (consistent with the parallel view of writing) outperformed the single-distribution models.

The two distribution model assumes two data generating processes, one associated with the immediate demands of motor planning required for the production of a keystroke, and one that captures all upstream processing from message to abstract letter representation. A direct implication of parallel, cascaded processing is that the distribution over interkey intervals is not additive -- it is not a combination of time to motor plan plus time for upstream processing. The interval between keypresses is *either* determined by motor execution *or* by processing that occurred upstream of motor execution (in cases where provision of output from the upstream processes lags behind the rate at which it can be output by the fingers). Under a serial account -- where all planning necessary for production of next-text occurs in the interkey interval immediately before output of -- interkey interval will be the sum of times for each processing step required for generation of that text. Both accounts predict longer mean interkey intervals at higher-order text edges (interkey intervals greater before sentences than before mid-sentence words, and before mid-sentence words than before mid-word characters). This has been consistently observed in a number of previous studies [@torrance2016adolescent; @wen02; @mohsen2021second; @miller2006pausing; @xu2017analyzing; @miller2008psycholinguistic;@deane2015exploring]. However, the serial account does not permit the possibility of a distribution of short interkey intervals at higher-order edges: It strongly predicts that *all* sentence boundaries will be associated with interkey intervals that are longer than those required just for the motor planning of the next character. Under the parallel-processing account it is very likely that some -- perhaps a large majority -- of interkey intervals before sentences will be longer. However there will be a distinct subset that is drawn from a distribution associated just with interkey intervals necessary for motor execution. 

This is what we found. At all linguistic edges we found a distribution of interkey intervals with durations that, in previous research, have been attributed just to motor execution (refs). For mid-word interkey intervals, as might be expected, the mixture model predicted that the vast majority of interkey intervals fall within this distribution. Across the six datasets that we sampled, the central tendency for the duration of mid-word interkey intervals was broadly similar to mean mid-word interkey intervals observed in previous studies. Importantly, however, these short interkey intervals were also present at higher-order text edges. Across all datasets we found, at minimum, a non-trivial minority of sentence-initial interkey intervals were sampled from the short distribution (i.e. with durations that could only be associated with motor execution). In two cases -- for adult writers sampled in the PLanTra and Lift datasets -- the majority of interkey intervals fell within this distribution. Thus, although as might be expected there was a considerably increased tendency for longer interkey intervals at higher order boundaries: Planning associated with planning a new sentence is, probabilistically, much more likely to spill beyond output of the previous sentence and therefore affect duration of the sentence-initial interkey interval. However the presence of a non-trivial proportion of interkey intervals with a duration that is inconsistent with anything other than motor execution can only be explained with recourse to theories that permit preparation in parallel with preceding output.

Our results showed that the hesitation probabilities are largely identical before sentences and before words, which suggests that writers frequently plan the next word and even sentence in parallel to production -- consistent with the parallel view of writing -- which mitigates the need to pause to plan up-coming linguistic information.   

This parallelism was evident even in the youngest writers in our data pool (C2L1; mean age: 11.8 years). As might be expected for children who compose predominantly by handwriting and whose typing skills will still be developing, motor execution rate (mean duration of fluent transitions) was substantially slower compared to the more experienced typists in other datasets. In all other respects, however, findings for this dataset were similar to that of other datasets and consistent with parallel processing. A two-distribution mixture model provided best fit to these data. At both before-word and before-sentence locations a non-trivial number of interkey intervals were within the short distribution - i.e. at durations too short to permit lexical retrieval or syntactic planning.    Probability of longer intervals was greater before-sentence and before-word transitions compared to mid-word transitions. This is interesting because, for example, @olive2014toward described a parallel model that operates  in a serial fashion for inexperienced or struggling writers, explained on the basis of task demands that reduce the ability to plan in parallel to processing which leads to a serialisation of planning units. However, the results presented in this paper suggest that pausing behaviour in young writers largely mirror results from more experienced writers: Pauses were both equally long and likely at before-word and before-sentence transitions but more likely compared to mid-word transitions. Also for L2 writers (PLanTra) we observe pausing patterns that do not resemble a serialised writing process as evidenced by a large number of fluent transitions at word and sentence boundaries.

We observed two more differences across datasets -- other than the patterns summarised above for C2L1 -- that are worth highlighting. Both can largely be explained on the basis of differences associated with the population (writing competence / experience) that these samples were obtained from and text genre they were asked to produce [see also @conijn2019understanding]: The first exception concern the GE2 and SPL2 datasets: pauses were more likely to occur before sentences than before words; this difference was absent in the remaining data sets. **TODO: I don't have an explanation for this.** Second, pauses at before-sentence locations were not always longer than before words or mid-word; specifically there were two exceptions: (1) sentence-initial hesitations were not longer than word-initial hesitation for the C2L1 dataset possibly because these sample of young inexperienced writers tend to use a more localised word-level planning strategy for text production. (2) pause durations did not vary across transition locations in the LIFT dataset. The absence of a difference could be explained as specific to the writing task because, in synthesis, there is less need for planning content and text structure: the structure is often kept similar to the source in synthesis writing [“structural isomorphism”’, @hidi1986producing]. However, the results of the PLanTra dataset rule out this possibility: there was evidence for longer hesitations at larger linguistic edges for a text simplification task that also does not require planning of contents or generating new sentence structures. 

An observation that was not strictly predicted by the parallel view is that the unconstrained mixture model M5 that allowed the distribution over durations of fluent transitions to vary between transition locations showed a higher predictive performance. This can be explained on the basis of low-level keyboarding activity: It is possible that letter bigrams are systematically produced faster than transitions between space and a subsequent letter -- as in before-word transitions -- or shift -- at before sentence locations. This is for two reasons: first, and importantly, highly frequent bi- and even trigrams may be stored, retrieved and executed as one motor code [@behmer2016crunching; @grudin1982digraph; @ostry1983determinants; @terzuolo1980determinants] because of the strong association between letters. This association reduces the length of transition durations. It is less likely that the same association exists for space-letter and space-shift pairs. Second, in two datasets (PLanTra, LIFT) before-sentence transitions are the sum of the transitions between space, shift and the following character key and therefore necessarily longer than other transitions. We found no evidence for the latter possibility (see Results section and Appendix \ref{key-combination-effect}).

A possible concern with our result -- that two-distributions mixture models showed substantially better predictive performance -- is that as mixture models have more parameters they might always outperform single-distribution models. This concern was preempted by using cross-validation techniques for model comparison which is preventing model overfit. In addition we used a simulation approach to compare a single distribution model and a two distributions mixture model. We simulated two datasets that were either based on a single distribution data-generating process or a process with a two-distributions process. This approach allows us to test the predictive performance of models in a context where we know the true underlying data generating process -- a single distribution vs a mixture of two distributions -- and we can test to what extent these models can successfully uncover the true parameter values. Importantly, we can test the performance of a mixture model for data that come from a single process. Modelling details can be found in Appendix \ref{simulation}. As might be expected, we found that the two-distribution mixture model was successful at uncovering the parameter values of the data generated with a two-distributions mixture process; we observed the same for the single-distribution model applied to the data generated with a single distribution process. Parameters were not successfully uncovered when we switched model type and dataset. Importantly though, cross-validation rendered a substantially higher predictive performance for the mixture model compared to the single-distribution model for data simulated from a two-distributions mixture process, but not when applied to data based on a single-distribution process. Therefore we can rule out the possibility that the statistical support for the two-distributions mixture-models can be explained on the basis of their larger number of parameters (i.e.model overfitting). 

Throughout this paper we assumed that hesitations reflect mental planning of upcoming ideas and encoding of linguistic units. Alternatively, at least some if not all pauses in the writing process might be the result of reading or looking back into previously produced text. There is limited research that used eye tracking to investigate regressive gaze behaviour during writing [@alamargot2010using; @beers2010adolescent; @chukharev2019combined; @de2018exploring; @torrancea; @van2010reading]. There are at least four reasons why eye movements away from the inscription point might occur during writing: First, reading is necessary for revision (i.e. writers must check if writing goals have been met). Second, writers might look for or correct spelling or grammatical errors. We removed transitions that terminated in an editing operation so the pauses we detected are unlikely to reflect revisions of the previous produced text. Third, writers might look at the source they are writing from. For two datasets (PLanTra, LIFT) which involved writing from sources, we removed transitions that were made when the source (rather than the writing document) was in focus.^[As for PlanTra, most participants copy-pasted the source text into their word log. In other words, pauses might to some extent result from reading the source text.] Fourth, writers might use text to cue or reinstate ideas after interruption of the writing process [@johansson2010looking; @hayes2013new].

As for the fourth reason for why writers might look back in their text: frequencies of lookbacks during writing follow a similar pattern as the one we observed for pausing: for example @torrance2016reading reported that lookbacks appear with a frequency of 45% before sentences, 12% before words and 5% within words of which 36% were associated with sustained reading but mostly less patterned forward and backward saccades between words ["hopping", see also @chukharev2019combined]. In contrast to this observation -- that lookbacks are more frequent before sentences compared to words -- we found that pauses appear equally often before sentences and words under our two-distributions mixture-model. Finally, even though reading is likely to explain some proportion of our results, lookbacks in previously written text are overall rare, certainly in samples of university students [@torrance2016reading; @chukharev2019combined]. Also, pause frequency did not change when the produced text was masked (see comparisons for the CATO and GE2 data in Appendix \ref{masking-effect-cato-ge2}), and therefore if reading previously produced text was not possible.


A practical advantage of the mixture-model approach [also @roeser2021modelling] is that we are not required to stipulate interval thresholds as plausible candidates for lower pause bound to handle the complex distribution of latency from spontaneous text production. Such thresholds are widely used by writing researchers, a strategy that was inherited from early research in speech production [for review see @rochester1973significance], with studies dating back to at least the mid 1990s [@foulin1998extent]. There is one central problems with this approach: A threshold requires a definition of what passes as a pause [@wen06;@van2016keystroke], i.e. a pause criterion threshold often set to 2 secs [@chanquoy1996writing; @kaufer1986composing; @sullivan2002self; @wen02] or some other lower bound [@chukharev2014pauses; @connelly2012predicting; @leijten2013keystroke]. Even if these thresholds were adjusted relative to factors such as writing medium, experience of writer, and text location of pause [see e.g. @wen06] they would be arbitrary. For example, a sentence-initial pause of 2 secs has a very different interpretation from a 2 secs pause that occurs before or within a word. Our current understanding of the processes that underlie text production does not provide a strong theoretical basis on which to make this decision. So while a 2 secs threshold undoubtedly captures an interesting distinction -- processing that occurs in the range zero to 2 secs is very likely to be qualitatively different from processing that takes more than 2 secs. However the same could be argued for any threshold between perhaps 250 msecs and 10 secs that a researcher might care to choose [@chenu2014interword]. Mixture models provide a principled statistical framework that allows the researcher to model behavioural data that come from a combination of cognitive processes without imposing threshold values [see also @almond2012preliminary; @baaijen2012keystroke; @hall2022constructing; @li2021identifying].

