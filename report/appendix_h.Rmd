## Simulation

A possible concern with these results -- substantially better predictive performance for bi-modal mixture models -- is that, in principle, as the mixture model has more parameters it might always lead to a better fit. We addressed this concern before by using cross-validation techniques for model comparison which is preventing overfitting models. To address this concern we repeated a comparison for a uni-modal model and a bi-modal mixture model for two sets of simulated data that were simulated either with a uni-modal or bi-modal process at heart. In other words, this allows us to test the predictive performance of our models in a context where we know the true underlying data generating process -- uni-modal vs bi-modal -- and we can test whether these models can successfully uncover the true parameter value.

In particular, the first data set was simulated using a bi-modal mixture model with two mixture components similar to the process described above (equations in \ref{eq:bimodcon} and \ref{eq:bimoduncon}). This process and the corresponding Bayesian model is summarised in equation \ref{eq:simmog}.

\begin{equation}
\begin{aligned}
(\#eq:simmog)
\text{y} \sim\text{ } & \theta \cdot \text{logN}(\beta + \delta, \sigma^2_1) +\\
& (1 - \theta) \cdot \text{logN}(\beta, \sigma^2_2)\\
\text{constraint: } & \delta, \sigma_\text{2}^2, \sigma_\text{1}^2>0\\
		& \sigma_{1}^2 > \sigma_{2}^2
\end{aligned}
\end{equation}

This model is largely identical to the models before but reduced to its main parameters (but not mixed effects for participants). The model includes two log-normal distributions with a mixing proportion $\theta$ of which the distribution of shorter values has a mean of $\beta$ and a standard deviation $\sigma^2_2$; the second distribution of longer values is constrained to have a mean that is larger by a factor of $\delta$ and has a larger standard deviation $\sigma^2_1$.

The second data set was generated with a uni-modal log-Gaussian process. The model and its corresponding Bayesian model is summarised in equation \ref{eq:simuv}.

\begin{equation}
\begin{aligned}
(\#eq:simuv)
\text{y} \sim\text{ }& \text{logN}(\beta, \sigma^2)\\
\text{constraint: } & \sigma^2>0
\end{aligned}
\end{equation}

Again, this model is a simplified version of the uni-modal models used in the main analysis. The model assumes a log-Gaussian distribution with a mean parameter $\beta$ and a standard deviation $\sigma^2$.

The parameter values used for each of the two data simulations can be found in Table \ref{tab:simparam}. The simulated data are visualised in Figure \ref{fig:simdata}. Parameter values were chosen so that the simulated data are roughly similarly distributed to keystroke transitions.

```{r simdata, fig.cap= "Data simulated with a bi-modal (grey) and a uni-modal (yellow) random data generating process. The x-axis showing the outcome y was log-scaled for visability.", fig.height=3.5, fig.width=5}
files <- list.files("../mixture-model-sim/data", full.names = T)

map_dfr(files, ~read_csv(.) %>% 
        mutate(Dataset = str_remove_all(.x, "../mixture-model-sim/data|/|.csv" ))) %>%
  mutate(across(Dataset, ~recode(., mogdata = "bi-modal", lmdata = "uni-modal"))) %>% 
  ggplot(aes(x = value, colour = Dataset, fill = Dataset)) +
  geom_density(alpha = .25) +
  scale_colour_colorblind() + 
  scale_fill_colorblind() +
  scale_x_log10(labels = ~format(., big.mark = ",")) +
  theme(text = element_text(size = 10)) +
  labs(colour = "Data process", 
       fill = "Data process", 
       x = "y", 
       y = "Density")
```

For each of these two data sets we simulated 1,000 observations. We run 2 models -- a bi-modal mixture model and a uni-modal model -- each for both data sets. Models were run with 3 chains, with each 6,000 iterations of which 3,000 were warmup. Estimates with 95% probability intervals are shown in Table \ref{tab:simparam}. The parameters are shown by type of data generating process along with the true parameter values. Parameter value estimates are shown by type of Bayesian model. The results show that either of the two Bayesian models succesfully uncovered the model parameters of the data with its corresponding data generating process, as shown in Table \ref{tab:simparam}, but less so when the model was applied to data generated with the incorrect underlying process. Particularly the mixing proportion $\theta$ and the slowdown parameter $\delta$ were not uncovered at all by they uni-modal model. 


```{r}
mog1 <- read_csv("../mixture-model-sim/stanout/mog_mogdata.csv") %>% 
  mutate(data = "mog")
mog2 <- read_csv("../mixture-model-sim/stanout/mog_lmdata.csv") %>% 
  mutate(data = "lm")
lm1 <- read_csv("../mixture-model-sim/stanout/lm_lmdata.csv") %>% 
  mutate(data = "lm")
lm2 <- read_csv("../mixture-model-sim/stanout/lm_mogdata.csv") %>% 
  mutate(data = "mog")

mog_sim <- bind_rows(mog1, mog2) %>% 
  summarise(across(value, list(est = mean,
                               lo = lower,
                               up = upper),
                   .names = "{.fn}"),
            .by = c(name, data)) %>% 
  mutate(across(where(is.numeric), ~round(., 2)),
         across(where(is.numeric), ~ifelse(str_detect(name, "prob"), dezero(., 2), .)),
         across(est, ~str_c(., " [", lo, ", ", up, "]")),
         across(name, ~str_c("\\", .)),
         across(name, ~str_replace(., "a_e", "a^2_1")),
         across(name, ~str_replace(., "ap_e", "a^2_2"))) %>%
  select(-lo, -up) %>% 
  pivot_wider(names_from = data, values_from = est) %>% 
  mutate(true = c(5, 1, .35, .25, .5),
         across(true, ~ifelse(str_detect(name, "prob"), dezero(., 2), .)),
         across(name, ~str_replace(., "prob", "theta"))) %>% 
  relocate(name, true) %>% 
  unite("name", name:true, sep = " = ")

lm_sim <- bind_rows(lm1, lm2) %>% 
  summarise(across(value, list(est = mean,
                               lo = lower,
                               up = upper),
                   .names = "{.fn}"),
            .by = c(name, data)) %>% 
  mutate(across(where(is.numeric), ~round(., 2)),
         across(est, ~str_c(., " [", lo, ", ", up, "]")),
         across(name, ~str_c("\\", .)),
         across(name, ~str_replace(., "a_e", "a^2_1")),
         across(name, ~str_replace(., "ap_e", "a^2_2"))) %>% 
  select(-lo, -up) %>%
  pivot_wider(names_from = data, values_from = est) %>% 
  mutate(true = as.character(c(5, .25))) %>% 
  relocate(name, true) %>% 
  unite("name", name:true, sep = " = ")

```




```{r simparam, results='asis'}
table <- bind_rows(mog_sim %>% mutate(model = "mog"),
                   lm_sim %>% mutate(model = "lm")) %>% 
  relocate(model) %>% 
  mutate(across(name, ~str_c("$", ., "$")))

names(table) <- c("Model", "Parameter with true value", "Bi-modal model", "Uni-modal model")

apa_table(table[,-1], 
          escape = FALSE,
      col_spanners = list("Estimate with 95\\% PI" = 2:3),
      caption = "Uncovered parameter estimates with 95\\% probability interval (PI) and true parameter values for each simulated data set and by model and their respective parameters.",
      align = c("l", rep("r", 2)),
      stub_indents = list(`Bi-modal data` = 1:5, 
                          `Uni-modal data` = 6:7))


```

We used LOO-CV to compare the predictive performance of the two models for each data generating process. The model comparisons can be found for each data generating process in Table \ref{tab:loossim}. The results rule out the possibility that the mixture model does always lead to higher predictive performance. Indeed, the mixture model showed a slightly lower predictive performance for the data that were generated with a uni-modal process. However, for the data generated with a bi-modal process, the mixture model shows a substantially higher predictive performance. In fact, the ratio of $\Delta\widehat{elpd}$ and its standard error, as metric for the strength of evidence [@sivula2020uncertainty], shows that the mixture model performs 11.6 times better than the uni-modal model. In comparison, for the uni-modal data, the uni-modal model performs only 0.77 times better than the bi-modal mixture model. Thus, as the difference $\Delta\widehat{elpd}$ between the model is negligible, the uni-modal is preferred by the law of parsimony. 


```{r loossim, results='asis'}
table <- read_csv("../mixture-model-sim/stanout/modelcomparison.csv") %>% 
  select(1:6) %>% 
  mutate(
#    elpd_se_ratio = abs(elpd_diff / se_diff),
    across(ends_with("diff"), ~round(., 1)),
    across(ends_with("loo"), ~round(., 0)),
    across(where(is.numeric), ~format(., big.mark = ",")),
    across(everything(), ~as.character(.)),
    across(everything(), ~str_trim(.)),
    across(everything(), ~str_replace_all(., "NaN", "--")),
    across(elpd_diff, ~str_c(., " (", se_diff, ")")),
    across(elpd_loo, ~str_c(., " (", se_elpd_loo, ")")),
    across(elpd_diff, ~str_replace_all(., "0.0 \\(0.0\\)", "--")),
    across(c(data, model), ~recode(., mog = "Bi-modal mixture model",
                                      lm = "Uni-modal model"))) %>% 
  select(data, model, starts_with("elpd")) 

names(table) <- c("Data", "Model", "$\\Delta\\widehat{elpd}$", "$\\widehat{elpd}$")

apa_table(table[,-1], 
          escape = FALSE,
      caption ="Model comparisons by data set. The top row shows the models with the highest predictive performance for each data generating process. Standard error is shown in parentheses.",
     note = "$\\widehat{elpd}$ = predictive performance indicated as expected log pointwise predictive density; $\\Delta\\widehat{elpd}$ = difference in predictive performance relative to the model with the highest predictive performance in the top row.",
      align =c("l", rep("r", 2)),
      stub_indents = list(`Data: Bi-modal mixture process` = 1:2, 
                          `Data: Uni-modal process` = 3:4))



```
